# Ref


- 高性能MySQL Kindle
- MySQL技术内幕：InnoDB存储引擎 Kindle
- [Mysql在大型网站的应用架构演变](http://www.cnblogs.com/Creator/p/3776110.html)



# 写在前面


这一篇综合总结的文章，融合了`Ref`中提到的重要内容，并重新整理了章节结构。以MySQL和InnoDB为中心，MyISAM为辅助。


由于两本涉及到MySQL的书都写于MySQL5.6版本之前，所以这里写的内容都只是讨论5.6版本之前的内容。


# MySQL架构与历史


MySQL被设计为一个单进程多线程的数据库，也就是说，MySQL的数据库实例在系统上的表现就是一个进程。


## MySQL逻辑架构


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690198-926720e2-6749-4460-a658-29989a14a255.png#align=left&display=inline&height=244&margin=%5Bobject%20Object%5D&originHeight=244&originWidth=174&size=0&status=done&style=none&width=174)


最上层的服务类似于网络服务的后端中类似的服务，负责连接处理、鉴权、安全等操作。


第二层服务是服务器层，也是MySQL架构中的核心，查询解析、分析、优化、存储过程、触发器、视图、内置函数等都在这一层实现。


第三层是存储引擎，负责数据的存储和提取。存储引擎有多种，各有优劣。MySQL服务器通过API与存储引擎通信，这个过程对上层查询过程透明。存储引擎API包含几十个底层函数，例如“查询某类记录”、“开始一个事务”。


- 连接管理
每个客户端连接会在服务端中拥有一个线程，服务端会通过线程池缓存线程。当客户端连接成功后，服务端会验证当前客户端的数据库权限。
- 优化、执行
MySQL会解析查询，并构建解析树，然后对解析树进行优化，包括重写查询、决定读表顺序、选择合适的索引。可以通过hint影响优化器决策过程；也可以通过explain查看服务器是如何决策的，从而更得当的修改自己的语句。
优化器不关心存储细节，它会向存储引擎请求一些统计信息（查询时间、表相关统计信息等等）。但是如果查询缓存存在，那么服务器不会再执行查询解析、 优化、执行的过程，而是直接返回查询结果。



## 并发控制


MySQL在两个层次上进行并发控制：服务器层、存储引擎层。


- 读写锁
读锁是共享的，互不阻塞；但是写锁是排他的。
- 锁粒度
在性能和并发安全性之间的平衡依赖于锁粒度的控制。因为加锁本身也是一件消耗较大的事情，如何尽可能减少锁消耗，减少并发冲突又能保证并发安全是提升性能的关键。
   - 表锁
对整张表加锁，采用读写锁。一般情况下，写锁比读锁具有更高的优先级。尽管存储引擎有自己的加锁策略，但是对于`ALTER TABLE`这类的语句，服务器会忽略存储引擎的设置，而直接使用表锁。
   - 行锁
行锁只对行加锁，最大程度的支持并发处理，但是带来了最大的锁开销。**行锁只在存储引擎中实现**，而服务器层并不了解存储引擎中的锁实现细节。所有存储引擎都以自己的方式实现了锁机制。



# MySQL存储引擎


MySQL中可以使用`show table status like 'user';`语句查看user表信息，例如Name、Engine、Rows、Avg_row_length、Max_data_length、Data_legth等信息，其中很多信息根据存储引擎的不同会不同。例如`Rows`对于MyISAM表就是真实值，而对于InnoDB表则是估计值。


需要注意的是，转换表的引擎会失去和原引擎相关的所有特性，例如从InnoDB转换为MyISAM再转回InnoDB将会丢失外键。


## InnoDB存储引擎


MySQL的默认事务型引擎，针对大量的短期事务设计。短期事务大部分都是正常提交的，很少被回滚。其性能和自动崩溃回复的特性使得其在非事务型存储的需求中也很流行，除非有特别的需求，否则都应先考虑InnoDB引擎。对于学习而言，InnoDB也是非常值得学习的，要比分散学习其他单独引擎获得更高的收益。


### InnoDB概览


- 数据存放在表空间（tablespace），这个空间是由InnoDB管理的黑盒
- 使用MVCC支持高并发，实现了四个标准的隔离级别。默认级别为`Repeatable Read`，并通过间隙锁（`Gap Lock`）防止幻读
- 基于聚簇索引。其对于主键索引性能很高，但是对于二级索引（非逐渐的索引）则必须包含主键列，所以如果主键列很大的话，其他所有索引都会很大。
- 崩溃恢复
- 支持外键
- 优化
   - 内存中创建hash索引以加速读操作的自适应哈希索引（Adaptive Hash Index）
   - 加速插入操作的插入缓冲区（Insert Buffer）
   - 为了高可用性使用两次写（Double Write）
   - 从磁盘读取数据时的可读性预测，预读（Read Ahead）



如果使用了InnoDB引擎，强烈推荐阅读官方手册中的[InnoDB事务模型和锁](https://dev.mysql.com/doc/refman/5.7/en/innodb-locking-transaction-model.html)一节。


### 多版本并发控制（MVCC，Multiversion Concurrency Control）


MySQL的大多数事务型存储引擎实现的都不是简单的行锁，基于提升并发性能的考虑，都实现了MVCC，但机制不尽相同。可以认为MVCC是行锁的变种，但是在很多情况下避免了加锁操作，开销更低。


MVCC通过保存数据在某个时间点的快照来实现。不同存储引擎的机制不同，典型的有乐观并发控制和悲观并发控制。下面通过InnoDB的简化版行为说明MVCC是如何工作的：


InnoDB的MVCC是通过在每一行后增加行创建版本号和行过期版本号两个隐藏列来实现的。每开启一个新的事务，系统版本号都会自动递增，并将其作为该事务的版本号。MVCC只工作在`REPEATABLE READ`和`READ COMMITTED`两个隔离级别下工作。下面简述在`REPEATABLE READ`隔离级别下具体是如何操作的：


- SELECT
InnoDB会将满足如下条件的记录作为查询结果返回：
   - 创建版本号 < 当前事务版本号
   - 删除版本号未定义 || 删除版本号 > 当前事务版本号
- INSERT
设置新插入行的版本号为当前事务版本号
- DELETE
设置删除行的过期版本号为当前事务版本号
- UPDATE
插入一行新纪录，设置当前事务版本号为创建版本号；同时设置当前事务版本号为原纪录的过期版本号



保存着两个版本号可以使得大多数纪录不需要加锁，但是占用了额外的空间，需要额外的维护工作。


### InnoDB体系架构


下图是InnoDB的体系架构，取自[MySQL 5.7 Ref - 14.4 InnoDB Architecture](https://dev.mysql.com/doc/refman/5.7/en/innodb-architecture.html)


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690228-b9b0a944-644e-4f8f-9756-a7923aeffb62.png#align=left&display=inline&height=565&margin=%5Bobject%20Object%5D&originHeight=565&originWidth=728&size=0&status=done&style=none&width=728)


#### 后台线程


MySQL通过多个后台线程处理不同的事务，主要有如下几个工作线程：


- Master Thread
核心线程，负责插入缓冲合并(insert buffer merge)、Undo页的回收等操作。
- IO Thread
IO Thread的主要工作是负责处理大量AIO请求的回调方法。
- Purge Thread
可以负责一部分Undo页的回收工作，减轻Master Thread的压力。
- Page Cleaner Thread
负责脏页刷新操作。



#### 缓冲池（内存池）


InnoDB存储引擎是基于磁盘存储的，并将记录按照页的方式进行管理。


缓冲池是内存里的一块区域，用以弥补磁盘速度对数据库的影响。缓冲池中缓存的数据页类型有索引页、数据页、undo页、插入缓冲、自适应哈希索引、InnoDB存储的所信息、数据字典信息等。


在数据库读取页的时候，先检查缓冲池中是否有该页，如果有，则命中；如果没有则读取磁盘上的页替换到缓存上，替换算法是LRU。整个过程类似于分页式虚拟内存。


在数据库中修改页的操作，则是首先修改页在缓冲池中的页，然后再以一定频率刷新到磁盘上。


##### InnoDB的改进LRU算法


缓冲池中的页面替换算法使用的是改进的LRU，相比普通的LRU，InnoDB不会每次都将新页面插入到LRU列表首部，而是插入到midpoint（默认列表尾部37%，通过参数`innodb_old_blocks_pct`配置）的位置，这之前的列表称为new列表，这之后的列表称为old列表。可以将new列表中的页理解为活跃热点页。


为什么要采取midpoint的设计？这是因为如果直接将读取到的页放到列表首部，那么某些SQL操作可能会使缓冲的页频繁刷出，产生抖动。例如全表扫描这类查询，需要访问很多页甚至全部的页，但这些页仅在这次查询中有效而不是活跃的热点数据，如果这些页直接插入到首部，则会将真正的热点页从列表移除。


##### Free列表


LRU列表用来管理已读取得页，当数据库刚启动时，LRU列表是空的，所有的页都存在Free列表中。当需要从缓冲池中分页时，首先检查Free是否有可用的空页，如果有则将该页从Free列表移除，加入到LRU中；如果没有，则淘汰一个LRU列表末尾的页，将该内存空间分配给新页。


##### Flush列表


在LRU列表中的页被修改后，该页称为脏页（dirty page）。数据库会通过Checkpoint机制将脏页刷新回磁盘，而Flush即为脏页列表。需要注意的是，脏页同时存在于LRU和Flush两个列表中。


#### 重做日志缓冲


除了内存缓冲池，InnoDB还有单独的重做日志缓冲（redo log buffer）。引擎会首先将重做日志信息放入缓冲区，再按一定频率将其刷到重做日志文件。


重做日志缓冲池默认大小8MB，但是由于会频繁刷新，所以足够使用。重做日志缓存在以下三种情况（Checkpoint）下会会被刷新到外部磁盘中:


- Master Thread每秒定时刷新
- 事务提交前会将日志缓冲刷新到重做日志文件
- 当重做日志缓冲池剩余空间小于1/2时，强制刷新



#### Checkpoint


为了避免数据丢失，当前的事务数据库系统普遍采用了`Write Ahead Log`策略，即当事务提交时，先写重做日志，再修改页。一旦发生宕机，可以通过重做日志完成数据恢复。


Checkpoint指的是强制将脏页刷新回磁盘的检查点。这主要是为了避免重做日志无限增长所做的优化。刷新时，InnoDB使用LSN（Log Sequence Number）标记Checkpoint版本。


### InnoDB关键特性


#### 插入缓冲（Insert Buffer）、修改缓冲（Change Buffer）


`Insert Buffer`虽然叫做Buffer，但是是实际上物理页上的结构，而非内存。插入缓冲实际上也是一颗B+树。它主要是用来将随机IO较多的索引插入操作转化为顺序IO的缓冲写入操作，等到闲时再由后台线程将插入缓冲内容合并（merge）进真正的索引页，以降低IO时间，**提升性能**。


InnoDB引擎对于非聚集索引的插入或更新操作，不是直接插入到索引物理页上，而是分如下两种情况：


- 如果索引页在缓冲池中，则直接插入
- 如果索引页不在缓冲池中，则先将其写入到插入缓冲中，随后由后台线程合并（merge）到索引页中



使用插入索引需要同时满足以下条件：


- 索引是次级索引（Secondary Index）
- 索引不是唯一（unique）的
之所以限制这条是因为InnoDB如果需要检查唯一性势必要查找索引页，产生随机IO，这也就丧失了插入索引的意义。



##### 修改缓冲


修改缓冲是插入缓冲的升级版本，增加了对delete、update的支持，限制条件相同，工作方式类似。


对于delete和update，其工作方式如下：


1. 将记录标记为删除
1. 真正地删除记录



#### 两次写（Double Write）


两次写是为了保证数据页的可靠性，**提升安全性**。


当数据库宕机时，可能InnoDB正在写入某页到表中，而这个页只写了一部分，这种情况称为部分写失效（partial page write）。


两次写的架构如下：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690264-6ddd753c-a974-48b7-87d9-10ca9ba13542.png#align=left&display=inline&height=499&margin=%5Bobject%20Object%5D&originHeight=499&originWidth=789&size=0&status=done&style=none&width=789)


两次写分两部分：内存中的2MB大小的内存缓冲和物理磁盘上1MB*2的两次写空间。2MB的大小对应了128个页，每个页大小为16KB


在对缓冲池脏页更新时，并不直接写磁盘，操作如下：


1. 通过memcpy将脏页复制到内存中的两次写缓冲
1. 分两次将内存数据写入到两个磁盘上的1M两次写空间，然后调用fsync立刻刷新，避免操作系统的内存缓冲
1. 完成doublewrite页的写入后，再将内存两次写的页写入到表空间文件中，此时写入是离散的



如果操作系统在页写入时发生了崩溃，则恢复过程中，InnoDB可以从共享表空间的两次写空间找到该页的一个副本，将其复制到表空间文件，再应用重做日志。


#### 自适应哈希索引（Adaptive Hash Index）


AHI会对满足如下条件的页构建哈希索引：


- 对某一页进行了**连续**超过100次**访问模式相同**（查询条件完全一致）的查询
- 页通过该模式访问了N次，其中N=页中记录*1/16



InnoDB文档显示，AHI可以将读取和写入提速2倍，将辅助索引的连接操作性能提高5倍。


#### 异步IO（Async IO）


- 用户可以在发出一个IO请求后再发出其他的IO请求，全部IO请求发送完后，等待所有IO操作完成
- AIO可以进行IO合并操作，如果AIO发现有连续的三个页面的IO请求，那么AIO会将其合并为一个请求。



### InnoDB文件结构


InnoDB数据都逻辑地存储在表空间（tablespace）中，表空间由由段（segment）、区（extent）、页（page）组成。图例如下：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690193-1bc4332d-48f3-4c20-a1d2-7b1ebc1ca4cd.png#align=left&display=inline&height=508&margin=%5Bobject%20Object%5D&originHeight=508&originWidth=748&size=0&status=done&style=none&width=748)


- 段分为数据段、索引段（叶子节点段+非叶子节点段）、回滚段等等
- 区是由连续页组成的空间，区大小固定为1MB，由连续的页组成
- 页大小默认16KB，可以通过设置为4K/8K/16K
- 行，行结构如下：
![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690492-85b1367a-9ff8-42e5-87cd-ab9d20731bc9.png#align=left&display=inline&height=73&margin=%5Bobject%20Object%5D&originHeight=73&originWidth=749&size=0&status=done&style=none&width=749)



## MyISAM存储引擎


- 非事务引擎
- 不支持崩溃恢复
- 不支持行级锁，只会对整张表加锁
读取时对读到的表加共享锁，写入时则对表加排他锁。但在由读取查询时可以往表中插入记录，称为并发插入（Concurrent Insert）。
- 支持全文索引（一种基于分词创建的索引）
- 压缩表
如果表在创建并导入数据后不会再修改，那么可以采用MyISAM压缩表。压缩表可以极大减少磁盘空间占用，减少磁盘I/O从而提高查询性能。



## InnoDB与MyISAM对比


todo


## MySQL内建的其他存储引擎


- Archive
对高速插入和压缩做优化的简单引擎，非事务型
- CSV
可以将普通CSV文件作为MySQL表处理，不支持索引。其作为一种数据交换机制非常有用
- Memory
适用于快速访问、无修改需求且无需持久化的存储。Memory引擎将数据存储在内存中的引擎，表结构会持久化。适合查找映射（例如邮编州名映射）、保存数据分析中间数据等需求。
Memory支持Hash索引，查找很快。但是使用表级锁，并发性能很低。且不支持BLOB和TEXT字段。
- 面向列的存储引擎
MySQL默认是面向行的，但是也有Infobright这一面向列的存储引擎，该引擎在数十TB数据下工作良好，设计用于数据分析及数据仓库应用。但是如果遇到查询不能使用面向列模式执行，则需要在服务器层转化为按行处理，这个过程会很慢。且使用Infobright需要对MySQL服务器进行定制以适应面向列存储的需要。



# 日志文件


## 慢日志（Slow Query Log）


MySQL启动时可以设定一个阈值，它会将运行时间超过该值的所有SQL语句记录到慢日志中。可以通过检查该文件确认是否有语句需要优化。


## 二进制日志（Binlog）


二进制日志记录了数据库执行更改的所有操作，主要作用有如下几种：


- 恢复（Recovery）：若遇到宕机，数据库数据尚未写入，则数据库可以通过二进制日志恢复这部分数据
- 复制（Replication）：其原理于恢复类似，用于备库同步主库数据
- 审计（Audit）：用户可以通过二进制日志进行审计，判断是否有注入攻击



二进制日志可以以行的方式或查询语句的方式存储变更。


其文件格式为二进制，需要使用MySQL提供的mysqlbinlog查看。如果是以查询语句方式存储的，则可以看到语句信息；如果是以行的方式存储的，则看到的信息时不可读的乱码。


## 错误日志（Error Log）


错误日志记录了MySQL启动、运行、关闭过程。遇到问题应该首先查看该文件定位问题。


## 查询日志（Log）


查询日志会记录所有的MySQL数据库请求信息，甚至是`Access denied`这类。


# Schema与数据类型优化


## 数据类型


### 实数类型


MySQL既支持精确类型，也支持不精确类型。精确类型有DECIMAL，不精确类型有FLOAT和DOUBLE。MySQL会根据列的精度要求自动选择底层数据类型。所以建议不指定MySQL的精度，强制MySQL使用指定的数据类型。


DECIMAL用于存储精确小数，但是需要额外的存储空间和计算开销。


FLOAT和DOUBLE类型使用标准浮点运算进行近似计算，有浮点误差，但是由于硬件原生支持浮点运算，速度较快。


### 字符串类型


#### VARCHAR和CHAR类型


VARCHAR用于存储可变长字符串，其开头使用额外的1或2个字节存储字符串长度。但是在操作中创建临时表时，MySQL不能确定结果集中最长的列，所以会为每一行的该列分配最大长度的空间，其结果就是排序速度降低且占用内存。


CHAR类型是定长的，MySQL总是根据定义分配足够的空间。


#### BLOB和TEXT类型


BLOB和TEXT都是存储很大的数据而设计的字符串数据类型，唯一的区别在于BLOB采用二进制方式存储而TEXT采用字符方式存储。


与其他数据类型不同，MySQL把BLOB和TEXT当作一个独立的对象处理，当其值太大时，InnoDB会使用专门的“外部”存储区域存储该值，而对应列位置存储的是指针。


MySQL只能对这两个类型的开始一部分进行排序，无法在对全部长度的字符串上进行索引。


### 日期与时间类型


MySQL能存储的最小时间粒度为秒。


MySQL提供了两种日期类型：DATETIME和TIMESTAMP。


DATETIME能保存1001年到9999年范围内的值，精度为秒。它把日期和时间封装到YYYYMMDDHHMMSS的整数中，与时区无关。使用8字节。


TIMESTAMP保存的是GMT时间戳，只使用4个字节，保存范围为1970到2038年，其显示值依赖于时区。该类型的列默认`NOT NULL`


### 位类型


使用频率很低，不详细讨论。需要注意的是MyISAM会确实使用位存储数据，可以节省空间。而InnoDB会选择足够存储的最小的整数类型存储，并不能节省空间。


## 优化


### Schema设计建议


- 使用更小的数据类型：例如使用TINYINT而非INT
需要注意的是，`TINYINT(1)`和`INT(1)`的不同，TINYINT占用8bit，INT占用64bit，而括号里的数值并不限制该字段的存储范围，而只是告知一些工具（例如MySQL客户端）这个字段的显示范围，对于存储空间来说，`INT(1)`和`INT(20)`是相同的。
- 使用简单的数据类型：例如使用INT而非VARCHAR
- 避免使用NULL
NULL值会使索引、索引统计等变得更复杂，且需要更多的空间来存储。如无必要，不要使用NULL；但是有必要的话，也可以使用。
使用`NOT NULL`带来的性能提升比较小，调优时无需优先考虑此点，应更多地从其他角度先下手。
- 主键列使用越简单的数据类型越好并且应该避免随机值
   - 简单列的空间消耗小
   - 简单的数据类型在查找比较的操作（一般是索引查找）中更快
   - 随机值会增加随机IO，对于机械硬盘而言速度远慢于顺序IO
- 避免太多的列
行数据从存储引擎到服务器编解码的过程代价很高，过多的列会导致性能下降。
- 避免查询中过多的关联。
`高性能MySQL`给出的建议是单个查询的关联控制在12个以内。
- 适当的反范式化



使用适当的冗余数据避免查询关联，对于提升速度有好处但是会增加维护的复杂性。


### 使用缓存表


对于一些不需要实时更新的数据，例如网站访问量、最热帖子这类的，可以使用单独的缓存表保存，定时更新，而不是每次都去扫描全表。


#### 一个计数器表的小例子


对于需要实时更新的计数器表，可以用如下这个小trick实现。


一般情况下，对于计数器，我们都会存储一行，如下：


```sql
create table hit_counter(
	cnt int unsinged not null
) engine=InnoDB;
```


然后每次点击更新计数器


```sql
update hit_counter set cnt = cnt+1;
```


但是这样在高并发下，这个计数器会产生大量的争用，此时可以在表中准备多个计数槽`slot`，每个更新语句随即更新一个槽，而其统计结果就是所有槽的值的和，如下：


建表语句：


```sql
create table hit_counter(
	slot_id tinyint not null primary key,
	cnt int unsinged not null
) engine=InnoDB
```


初始化添加100个slot。


更新语句如下：


```sql
update hit_counter set cnt = cnt+1 where slot_id = rand()*100;
```


获取统计结果的语句：


```sql
select sum(cnt) from hit_counter;
```


除此以外还有类似的按天分离计数器、按帖子分离计数器等等或综合使用，例如如下更新：


```sql
insert into daily_hit_counter(day, slot, cnt)
values (current_date, rand()*100, 1)
on duplicate key update cnt = cnt+1;
```


### 加快`alter table`的速度


MySQL执行大部分表结构修改都是用新结构创建一张新表，再从旧表查询出所有数据，插入到新表中，然后删除旧表。这是一个十分耗时的工作。


一般而言，大部分`alter table`将导致MySQL服务中断，可以使用影子拷贝的方法避免这种情况。影子拷贝指的是新建一个使用新结构创建的临时表，将旧表数据复制过来后再通过一个“将旧表改名为备份表并将新表改名为旧表名”的原子操作保证无服务中断的切换。


也可以通过直接修改表描述文件的方法修改表结构，但是很危险！


# 查询


## 查询过程


MySQL的查询过程如下：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690543-d6087483-2be3-4eec-9852-678a23eefcf8.png#align=left&display=inline&height=457&margin=%5Bobject%20Object%5D&originHeight=457&originWidth=589&size=0&status=done&style=none&width=589)


### 1. 客户端、服务端通信


客户端与服务端的通信时半双工的，客户端发送查询请求后只能等待服务端响应并接受完整的结果，而不能再接收前面几条结果后，让服务器停止发送。服务端需要完整发送完所有数据才能释放相应资源。


MySQL连接会有一个状态表明当前查询属于生命周期的哪个阶段:


- Sleep
服务端线程等待客户端请求。
- Query
线程正在执行查询或将结果发送给客户端。
- Locked
线程正在等待服务器层的表锁。在存储引擎级别实现的锁（例如InnoDB中的行锁）并不会体现在线程状态中。
- Analyzing and statistics
线程正在收集存储引擎统计信息并生成查询计划。
- Sorting Result
- Sending data



### 2. 查询缓存


通过内存中大小写敏感的哈希表实现的缓存，在解析语句之前，MySQL会检查这个查询是否命中了缓存。


### 3. 语法解析与预处理


1. 查询的语法分析
检查查询的语法规则，并将其解析为解析树。
1. 预处理器的语义分析
检查解析树的语义，例如数据表或数据列是否存在等等。
1. 解析树的权限验证



### 4. 查询优化器


MySQL使用基于成本的优化器，他将尝试预测一个查询使用某种执行计划的成本，并选择成本最小的一个。


但是很多原因会导致优化器选择错误的执行计划：


- 统计信息不准确，例如InnoDB因为MVCC架构并不能维护数据表行数的精确统计信息
- 执行计划的成本估算不等于实际执行成本，因为优化器没办法预测缓存和具体的IO次数
- 优化器不考虑其他并发执行的查询
- 优化器不考虑不受其控制的操作的成本，例如执行存储过程、用户自定义函数等



优化器的优化策略可以简单的分为静态优化和动态优化。


- 静态优化
静态优化，优化器通过直接对解析树分析完成优化，不依赖特别的数值。例如将简单的代数变换将where条件转化为另一种等价形式。
- 动态优化
动态优化和查询上下文有关，如where条件中的取值、索引中条目对应的数据行数等。这需要每次执行时都重新评估。



下面介绍一些优化类型：


- 重新定义关联表顺序
- 将外连接转化为内连接
外连接的缺陷在于必须全表扫描，而有一些where条件、库表结构可能会让外连接等价于一个内连接，MySQL能够识别这点并重写查询，从而将全表扫描转化为可以使用索引的情况。
- 优化COUNT()/MIN()/MAX()
索引可以帮助优化此类表达式，如果要找到某一列的最小值，只需要查询对应B+Tree的最左端记录，其他同理。
- 覆盖索引扫描
当索引中的列包含所有查询中需要使用的列的时候，MySQL可以直接使用索引返回需要的数据，而无需查询行。
- 子查询优化
MySQL在某些情况可以转化子查询，减少多个查询多次对数据进行访问。
- 提前终止查询
当发现已经满足查询需求时，MySQL总能够立刻终止查询。典型的例子是LIMIT、DISTINCT、NOT EXIST、LEFT JOIN。
- 等值传播
对于多个表中的相互关联的字段，MySQL可以自动地把其中一个列的where条件传递到另一个列上，例如:
```sql
select film.film_id
from film 
	inner join film_actor using(film_id)
where film.film_id > 500;
```

- 
这个查询中的film_id的限制条件可以从film表传播到film_actor表中。
- 使用等价规则变换
合并表达式、移除恒成立和恒不成立。例如`5=5 and a>5 and a<b and b=c and a=5`将被改写为`a=5 and b>5 and b=c`。
- 列表IN()比较
MySQL会将IN列表中的数据排序，然后通过二分查找的方式确定列中的值是否满足条件，这是一个`O(lgN)`的操作，相比遍历的`O(N)`要快一些。



上述的内容只是优化器优化策略中很小的一部分，如果确认优化器给出的不是最佳选择，并且自己清楚背后原理，可以使用HINT提示影响查询计划。


#### 关联查询优化


在后文查询执行引擎一章会介绍MySQL如何执行关联查询，此处介绍MySQL如何对关联查询进行优化。


关联查询优化是优化器最重要的优化，他决定了多个表关联时的顺序。通常多表关联的时候，可以有多种关联顺序来获得相同的执行结果，关联查询优化器则通过评估不同顺序时的成本（最直观的时需要扫描的行数）选择一个成本最低的关联顺序。


#### 排序优化


MySQL持有一个称为“排序缓冲区”的内存区域，如果需要排序的数据量小于排序缓冲区大小则直接在缓冲区内快排；否则将数据分块使用快排后再归并。


MySQL两种排序思路：


1. 两次读取，用于旧版本：只读出用于排序的列，排序完再根据索引值去读对应行。优点是能同时排序的行数变多，缺点是第二次读取会产生大量的随机IO。
1. 单次读取，用于新版本：直接读出所有列用于排序。优点是IO少，缺点是占用内存大从而导致同时进行排序的行较少。



#### 优化器的局限性


- UNION内层的查询无法接收到外层的LIMIT限制条件
例如对于`UNION`结果限制了`LIMIT 20`但内层没有限制，那么MySQL仍会查询出内层的所有结果，然后再取20个。
- 对于嵌套循环关联这类的查询，MySQL无法利用多核特性来并行执行查询
- MySQL不支持松散索引扫描
- MySQL不支持在同一个表上同时查询和更新



### 5. 查询执行引擎


MySQL通过执行计划完成查询过程，这个执行计划并不是字节码，而是一棵左侧深度优先的树。


再根据执行计划执行的过程中，MySQL为每一个需要的表创建了一个handler实例，通过特定handler便可以访问特定表中的数据和统计信息。


#### MySQL如何执行关联查询


MySQL认为每一次查询都是一次关联，标准的关联、子查询、甚至是单表select都可能是关联。


MySQL对于所有的关联都执行**嵌套循环关联操作**：先到一个表中循环取出单条数据，再嵌套循环到下一个表中寻找匹配的行，依次下去，直到找到所有表中匹配的行，返回查询中需要的各个列。


从本质上说，MySQL对所有类型的查询都以同样的方式运行。对于form子句中的子查询，限制性子查询并将其放到临时表中，再将临时表作为普通表（称之为“派生表”）对待。


查询过程例如如下查询：


```sql
select tb1.col1, tb2.col2
from tb1 inner join tb2 using(col3)
where tb1.col1 in(5,6);
```


可以使用如下“泳道图”表示：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690183-5673b376-5c3f-4ee5-9350-cf147644e9f2.png#align=left&display=inline&height=260&margin=%5Bobject%20Object%5D&originHeight=260&originWidth=422&size=0&status=done&style=none&width=422)


### 6. 返回结果给客户端


查询执行最后服务器会将结果返回给客户端，即使查询不需要返回结果集，MySQL仍会返回这个查询的一些信息，如该查询影响到的行数。


如果查询可以被缓存，MySQL再这个阶段会将结果放到查询缓存中。


MySQL返回结果集是一个增量的过程。对于关联查询，一旦服务器处理完最后一个关联表并开始生成第一条结果时，就可以开始向客户端逐步返回结果集了。这样做有两个好处：服务端不需要储存太多结果而浪费内存；客户端也可以第一时间获取结果。


## 查询性能优化


### 查询的时间都花在哪了？


从查询的生命周期来看，查询花费的时间主要包括如下几点：


- 网络请求
- 生成统计信息和执行计划
- 锁等待
- IO
- 计算（排序）



### 优化查询的手段


查询优化、索引优化、库表结构优化需要齐头并进。


对于低效的查询，要重点分析两点：


- 客户端是否请求了不必要的数据（多余的行或列）？
这会导致多余的网络带宽、列编解码时间消耗。
- MySQL**服务器层**是否分析了大量超过需要的数据行？
对于MySQL，最简单的衡量查询开销的三个指标为:
   - 响应时间
   - 扫描行数
   - 返回行数

对于过慢查询，MySQL会将其记录到**慢日志**中，对慢日志中的查询进行优化时优化查询的好方法。


#### where条件优化


MySQL能够使用下面三种方式应用where条件，由好到坏依次是：


- 在索引中使用wher条件过滤记录，在存储引擎中完成
- 使用索引覆盖扫描(Extra列出现`Using index`)返回记录，在服务器层完成，但是不需要再回表查询记录
- 从数据表返回数据，然后过滤不满足条件的记录(Extra列出现`Using Where`)，在服务器层完成，需要先从存储引擎读出记录再过滤



如果发现查询扫描了大量的行但是只返回了少数行，可以同下面的角度优化:


- 使用覆盖索引扫描
- 改变库表结构
- 重写复杂查询
   - 将一个大查询且分为多个小的查询
   - 分解关联查询，在应用程序中进行关联而非数据库，这样可以更高效地利用缓存、避免锁争用、降低数据库复杂度使其易于扩展



#### 优化子查询


尽量使用关联查询代替子查询。


#### 使用水位机制优化LIMIT分页


### 查询优化器提示 HINT


- `HIGH_PRIORRITY`/`LOW_PRRORITY`
- `DELAYED`
告知服务器该INSERT或UPDATE可以先被缓存，稍后再执行；此时服务器会将其缓存。这个HINT适用于日志这类场景。
- `STRAIGHT_JOIN`
- `SQL_SMALL_RESULT`/`SQL_BIG_RESULT`
- `SQL_BUFFER_RESULT`
- `SQL_CACHE`/`SQL_NO_CACHE`
- `FOR UPDATE`/`LOCK IN SHARE MODE`



# 索引


索引是在存储引擎层实现的，所以索引并没有统一的标准和工作方式，也并不是所有的存储引擎都支持索引。


## 索引实现


### B+Tree索引


一种针对顺序IO优化的数据结构。本章入无特殊说明均为InnoDB中的B+Tree索引


#### 数据结构


如下展示的是一棵高度为2的B+树，每页可存放4条记录。


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690443-f7899aac-b2ff-42fa-b515-04728a5f6ca5.png#align=left&display=inline&height=201&margin=%5Bobject%20Object%5D&originHeight=201&originWidth=756&size=0&status=done&style=none&width=756)


B+树中，所有的记录节点都是按键值大小顺序存放再同一层的叶子节点上，非叶子节点不储存记录，各个叶子节点相互连接。


##### 插入操作


B+树有三种插入情况：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690281-0e711ffb-2323-4348-891a-1784f1d96dc8.png#align=left&display=inline&height=327&margin=%5Bobject%20Object%5D&originHeight=327&originWidth=752&size=0&status=done&style=none&width=752)


以开始给出的B+树为例，插入键值28，此时可以直接插入，树结构此时如下：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690204-6aafd7a8-0034-41e8-9f65-1743619f7f59.png#align=left&display=inline&height=170&margin=%5Bobject%20Object%5D&originHeight=170&originWidth=749&size=0&status=done&style=none&width=749)


插入70，此时叶节点已满，但索引页节点未满，需要拆分叶节点，拆分规则是将需要插入的第三个叶节点从其中间拆分开，并将其中间节点的键值上浮到索引页中，树结构此时如下：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690287-69de8d34-ee69-4667-b4fc-33d9d21af741.png#align=left&display=inline&height=268&margin=%5Bobject%20Object%5D&originHeight=268&originWidth=749&size=0&status=done&style=none&width=749)


插入95，发现叶节点和索引节点都满了，所以依次拆分叶节点和索引节点，此时树结构如下：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690279-0c5dd0b0-9560-40c4-b2ea-0f2d038a1244.png#align=left&display=inline&height=306&margin=%5Bobject%20Object%5D&originHeight=306&originWidth=751&size=0&status=done&style=none&width=751)


可以看到，无论怎样变化，B+树总是平衡的。但是为了尽量减少页拆分（因为B+树是为了磁盘设计的，要尽量保证数据连续），B+树同样支持旋转。旋转发生在叶节点已满，但其左右兄弟节点未满的情况下。此时，B+树优先通过旋转的方法将记录转移到兄弟节点。


例如上述插入70的过程，如果考虑了旋转的操作，则会得到如下结果：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690363-186e13f7-d6e5-447f-a49d-7a23f97abcd9.png#align=left&display=inline&height=201&margin=%5Bobject%20Object%5D&originHeight=201&originWidth=756&size=0&status=done&style=none&width=756)


##### 删除操作


B+树使用填充因子控制树的删除变化，50%是填充因子可设置的最小值。


B+树的删除操作需要考虑如下三种情况：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690465-6951e652-dfef-4270-9132-d58c64742a1a.png#align=left&display=inline&height=205&margin=%5Bobject%20Object%5D&originHeight=205&originWidth=746&size=0&status=done&style=none&width=746)


仍然使用上一章插入了28、70、95以后的B+树为例，如果删除键值70，树结构此时如下：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690290-aba3751a-983c-450f-bc11-bc49ccc4e556.png#align=left&display=inline&height=339&margin=%5Bobject%20Object%5D&originHeight=339&originWidth=751&size=0&status=done&style=none&width=751)


接着删除25，这里需要注意的是将数据移动到页开始的位置，树结构此时如下：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690314-a0f3d037-d743-4049-b201-8be3bdb6689a.png#align=left&display=inline&height=342&margin=%5Bobject%20Object%5D&originHeight=342&originWidth=755&size=0&status=done&style=none&width=755)


删除键值60，此时叶节点的填充因子小于50%，需要合并页，树结构此时如下：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690252-06cfee43-f77e-4bfe-a417-3944778e3e45.png#align=left&display=inline&height=282&margin=%5Bobject%20Object%5D&originHeight=282&originWidth=752&size=0&status=done&style=none&width=752)


#### 聚簇索引


聚簇索引不是一种单独的索引类型，而是一种数据存储方式。


B+Tree只在叶节点存储值，InnoDB实现时使用了聚簇索引，也就是说，**主键**索引的叶节点并不单单存储的是索引值，而是存储了行记录。如果没有主键，InnoDB会选择一个唯一的非空索引代替，如果仍然没有，则会隐式定义一个主键。其结构如下图：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690256-dfa32f38-4916-4354-984a-19d0e906575f.png#align=left&display=inline&height=442&margin=%5Bobject%20Object%5D&originHeight=442&originWidth=206&size=0&status=done&style=none&width=206)


聚簇索引有着一个很重要的优点，它将相关数据聚集在一起，利于范围查询，将原本可能的随机IO转化为了索引叶子页上的连续IO。


但聚簇索引也有一些显著缺点：


- 在向已有数据间插入新行时，聚簇中的行可能需要移动，索引页也要可能会有分裂操作，这需要更多的IO和更大的磁盘空间，还会产生页内碎片。这也就是为什么主键最好不要随机生成，而应该和主键索引保持一致
- 插入速度依赖于插入顺序
- 增加二级索引的访问次数
二级索引不会保存行记录，而只保存了行的主键，所以访问需要先通过二级索引查找到主键值，再通过主键值在聚簇索引中查找数据行



#### 可以使用B+tree查询的类型


- 全值匹配
- 匹配最左前缀
- 匹配列前缀
例如`select from people where name like 'J%'`
- 精确匹配某一列并范围匹配另一列，范围匹配后续的列则不能再使用索引
【存疑，为啥，明明如果都有索引仍然能保证次级索引有序】个人猜测这个是MySQL服务层的限制，需要以后查阅资料



#### 优点


整体而言是降低了读的时间


- 索引减少了需要扫描的行数量
- 索引可以帮助排序
- 索引可以将随机IO变为顺序IO



#### 缺点


- 由于需要维护索引，插入和更新操作会消耗更多的时间
- 索引会占据额外的空间


#### 不能使用索引的场景

如果想要创建高性能索引，先要了解几种典型的不能使用索引的情况：

- 以`%`开头的模糊匹配
- 索引列是表达式的一部分，而非独立的列，例如`select actor_id from actor where actor_id + 1 = 5;`，或者在表达式中使用了函数等。
- 未能满足最左前缀：如果不满足最左前缀，索引不能被充分利用
- 范围匹配后的索引全部失效
- 对于需要访问大量表中数据的情况（例如三成四成以上的数据量），使用索引需要离散读取索引页，会产生大量的随机IO，但是如果直接进行全表扫描可能会比使用索引快得多，此时优化器会选择不适用索引。因此，设计索引时应该尽量把区分度大的列放在左侧

#### 设计、使用高性能索引

##### 使用合适的前缀索引基数 Cardinality

对于很长的字符串列，索引全部字符会让索引变得大而慢。这时选择合适的前缀索引就可以达到良好的**索引选择度**、加快索引速度、防止索引空间浪费，但是前缀索引无法再用来做`order by`、`group by`或覆盖扫描。

可以通过实验寻找合适的前缀值大小，如下例：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690516-cae04c1a-7e06-4def-8bde-4b68b79e6188.png#align=left&display=inline&height=248&margin=%5Bobject%20Object%5D&originHeight=248&originWidth=474&size=0&status=done&style=none&width=474)


有时也会利用到后缀索引，例如邮箱地址。MySQL并不原生支持后缀索引，但可以通过逆转字符串再建立前缀索引的方法来实现后缀索引。


##### 选择合适的索引列顺序


存储引擎无法利用非最左前缀的索引，所以索引列的顺序很重要。一般将选择性最高的列放到索引的最前列，将范围查询的列放到靠后的位置。


##### 使用索引扫描来做排序


当所有的列的顺序和`order by`子句的顺序完全一致，并且所有列的排列方向（倒序或正序）都一样时，MySQL才能使用索引来对结果做排序。


如果查询需要关联多张表，则只有当`order by`子句引用的字段全部为第一个表时，才能使用索引排序。这一点配合查询过程很容易想明白。


`order by`的限制与索引相同，都需要满足最左前缀的要求。


##### 避免在查询时使用多个范围条件


##### 多索引


例如，添加索引`(A,B)`后再添加索引`(B)`，这样对于需要使用`A`、`B`、`A/B`的查询都有索引可以使用。


### Hash索引


充分利用了随机IO的索引结构。MySQL中也只有内存引擎显式支持哈希索引；InnoDB会对热点数据建立自适应哈希索引（Adaptive Hash Index）加速，此过程无法显式干预。


哈希（Hash）索引基于哈希表实现，只对精确匹配的索引有效。对于每一行数据，存储引擎会对所有索引列计算一个哈希码（Hash Code），并在哈希表中为对应的哈希码存储指向数据行的指针。


哈希索引不能用与模糊查找、范围查找，且索引内并不存放行记录。


### 覆盖索引

当MySQL可以通过索引直接获得列的数据时，就不需要再查找聚簇索引获得数据了。这种覆盖了所有需要查询的字段的索引，称为覆盖索引。


### 全文索引

MyISAM支持字段上的全文索引，InnoDB不支持全文索引。


### 倒排索引

参考Elasticsearch相关的文章。


# 事务


事务是一组原子性的SQL语句，要么全部执行，要么全部不执行。在MySQL中，使用`START TRANSACTION`语句开始一个事务，然后要么使用COMMIT提交所有修改，永久保留；要么使用`ROLLBACK`撤销所有更改。


MySQL中使用了自动提交（AUTOCOMMIT）模式，也就是说，每一个查询都被当做一个事务执行提交操作，可以通过`SET AUTOCOMMIT = 0`禁用自动提交。


MySQL的服务器层不管理事务，事务由下层存储引擎实现，所以在同一事务中使用多种存储引擎是不可靠的。例如，事务中混合使用了事务型和非事务型的表，提交时不会出现问题，但在回滚时，非事务型表上的变更无法撤销。


事务中可能会发生数据争用，此时需要锁来控制事务对数据的访问顺序。


## 锁


### InnoDB中锁的类型


InnoDB实现了两种标准的行级锁:


- 共享锁（S Lock），允许事务读取一行数据
- 排他锁（X Lock），允许事务删除或更新一行数据



共享锁与共享锁之前不会导致线程阻塞，其他的任意组合都会导致线程阻塞。


InnoDB根据每个事务访问的页对锁进行管理，采用位图的方式，因此无论一个事务锁住页中一个记录还是多个记录，其开销都是一致的。


InnoDB在`INFORMATION_SCHEMA`架构下添加了三表`INNODB_TRX`/`INNODB_LOCKS`/`INNODB_LOCK_WAITS`可以查看事务、锁、锁等待情况，方便排错。


### 一致性非锁定读（Consistent Nonlocking Read）


一致性非锁定读指的是InnoDB引擎通过MVCC的方式读取当前执行时间数据库中的行。下图显示了这个过程：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690256-6f21e066-1ff5-4d1a-ae1b-8186f10bc461.png#align=left&display=inline&height=607&margin=%5Bobject%20Object%5D&originHeight=607&originWidth=738&size=0&status=done&style=none&width=738)


InnoDB的读操作不需要等待排他锁释放，而可以通过undo段读取到该行的快照数据，这部分数据是不需要加锁的，因为不可能有事务需要修改历史数据。


### 一致性锁定读


InnoDB对于select语句支持两种一致性的锁定读操作：


- `select ... for update`
该语句会向行记录上加排他锁。
- `select ... lock in share mode`
该语句会向行记录上加共享锁。



需要注意的是锁会在事务提交后释放，如果使用这两个语句，一定要将`AUTOCOMMIT`置0。


### 锁算法


- Record Lock
单个记录上的行锁。
- Gap Lock
间隙锁，锁定一个范围，但不包含记录本身。
- Next-key Lock
`Record Lock` + `Gap Lock`，同时锁定范围与记录



#### 锁降级


当范围内不会再插入新的记录的时候，`Next-key Lock`可能会降级为多个行锁，如下例:


先锁定了(10,11],(12,13]，此时插入新记录12，锁定范围变为(10,11],(11,12],(12,13]。若该列unique，则此时(10,13]这个区间不可能再有插入，则可以降级为对于11,12,13的行锁。


### 死锁


数据库中的死锁指的是多个事务争用统一资源并锁定对方占用资源从而导致的循环等待的现象。这里说的资源，一般来说是表或者行，也就是锁的对象。


数据库中通常通过死锁检测和死锁超时机制来处理死锁带来的问题。InnoDB通过等待图（waits-for graph）检测循环依赖来主动检测死锁，一旦发现有循环依赖存在，便将权重（与锁定的资源相关）最低的事务回滚。相对而言，死锁超时机制会导致慢查询，不如死锁检测。


## 事务的ACID特性


- 原子性 Atomicity
一个事务是不可分割的最小工作单元，要么全部提交成功，要么全部失败回滚。
- 一致性 Consistency
数据中总是从一个一致性状态转换到另一个一致性状态，数据库的完整性约束不会被破坏。
- 隔离性 Isolation
通常来说，一个事务所做的修改在最终提交以前对于其他事务是不可见的。但由于隔离级别设置的不同，也可能出现可见的现象，此时并不能算作严格满足了事务的隔离性。
- 持久性 Durability
一旦事务提交，其所做的修改就会永久的保存到数据库中。此时即使数据库崩溃，修改的数据也不会消失。但是实际上不存在百分百的持久性，持久性也分为很多级别。



## 隔离级别


SQL标准中定义了四种隔离级别，每一种级别都规定了一个事务中所做的修改，哪些在事务内和事务间可见的，哪些是不可见的。每种存储引擎实现的隔离级别不尽相同。MySQL中通过`SET TRANSACTION LEVEL [READ COMMITTED]`来修改隔离级别。
四种隔离级别如下：


- READ UNCOMMITTED 读未提交
事务的修改，即使在事务未提交的情况下，其他事务也可以看到，这种情况称为脏读。从性能上来说，该级别不会比其他级别好太多，但是缺乏其他级别的很多好处，很少使用。
- READ COMMITTED 读提交、不可重复读
一个事务开始时只能“看到”已经提交的事务所做的修改，避免了脏读。这种级别又被称为“不可重复读”，因为在一个事务的多次读取可能得到不一样的结果。
大多数数据库系统的默认隔离级别都是该级别，但MySQL不是。
- REPETABLE READ 可重复读
解决了脏读、不可重复读的问题，该级别保证了在同一个事务中多次读取同样记录的结果是一致的。但是会出现“幻读”的情况：幻读指的是一个事务读取某个范围内的记录时，另一个事务在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生“幻行”。InnoDB通过间隙锁`Gap Lock`和单行锁`Record Lock`的组合`Next-key Locking`解决了“幻读”问题，实际上已经达到了串行化的隔离级别。
可重复读是MySQL默认的隔离级别。
- SERIALIZABLE 串行化
最高的隔离级别，通过强制事务串行执行，避免了前面所说的幻读的问题。该级别通过在每一行数据上都加锁达到串行的效果，会导致大量的锁争用，实际很少使用。



总结一下：


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690328-ddc8dd11-8fdf-4b2c-ac73-526ee4d5e2ec.png#align=left&display=inline&height=144&margin=%5Bobject%20Object%5D&originHeight=144&originWidth=680&size=0&status=done&style=none&width=680)


## 事务的实现


事务的隔离性通过锁实现。而原子性、一致性和持久性通过`redo log`（物理日志）和`undo log`（逻辑日志）实现。


### redo log


重做日志又分为如下两部分：


- 内存中的`redo log buffer`，是易失的
- 磁盘中的`redo log file`，是持久的



InnoDB通过预写日志（Write-Ahead Log）实现事务持久性。在事务提交时，必须将事务的所有日志写入到重做日志持久化后，事务的提交才算完成。


#### 重做日志和二进制日志的不同


- 重做日志在InnoDB引擎层产生，而二进制日志在服务器层产生
- 重做日志只用于InnoDB引擎，而二进制日志用于任何存储引擎
- 重做日志在事务进行中不断写入，二进制日志只在事务提交完成后写入，下图可以很好的表明这个区别：
![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690293-ca14d606-f378-470c-82a8-58af1c12003f.png#align=left&display=inline&height=251&margin=%5Bobject%20Object%5D&originHeight=251&originWidth=740&size=0&status=done&style=none&width=740)



#### Log Block


重做日志都是以`Log Block`为单元存储的，每个block大小为512字节，这个大小与磁盘扇区大小相同，可以保证写入的原子性，所以不需要额外的doublewrite保护。（MySQL5.7上的`redo log`是分成了两个文件的，但不是doublewrite，只是用来循环写入的）


#### 重做日志刷新情况


`redo log`在如下几种情况会刷新到磁盘：


- 事务提交时
- 当log buffer有一半内存空间被使用
- log checkpoint



### undo log


undo日志是逻辑日志，之所以不能是物理日志，是因为并发系统中，有可能其他事务修改了某些记录，此时若当前事务回滚，它并不能使用物理日志直接覆盖这些记录，而是应该反向操作恢复自己对数据的变更。InnoDB的undo日志对insert生成delete，对update生成相反的update。


需要注意的一点是undo的过程会产生`redo log`，因为事务回滚的过程同样需要持久性保护。


undo日志的作用主要有两个：


- 事务回滚
为了实现事务的回滚操作，InnoDB还会记录逻辑修改的undo日志。
- MVCC
InnoDB的MVCC是通过undo日志完成的。当事务读取一行记录但该记录已被其它事务占用时，当前事务可以通过undo日志读取之前的行版本信息，实现非锁定读取。
由于这个功能的存在，InnoDB并不能在事务提交后就删除某个事物对应范围的undo日志，而是由独立的purge线程负责清除无用的undo日志。



## 分布式事务（XA事务）


分布式事务由一个或多个资源管理器（Resource Managers）、一个事务管理器（Transaction Manager）以及一个应用程序（Application Program）组成。


- 资源管理器：提供访问事务资源的方法。通常一个数据库就是一个资源管理器
- 事务管理器：协调参与全局事务的各个事务。需要和参与全局事务的所有资源管理器通信
- 应用程序：指定全局事务的操作



分布式事务使用两段提交（Two-phase Commit）的方式。


第一阶段，所有参与全局事务的节点开始准备（Prepare），告诉事务管理器他们准备好提交了。


第二阶段，事务管理器告诉资源管理器执行ROLLBACK还是COMMIT，如果任何一个节点显示不能提交，则所有节点都被告知要回滚。


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690362-f564e2ca-f70a-4b48-83ce-1aaa83a91c68.png#align=left&display=inline&height=345&margin=%5Bobject%20Object%5D&originHeight=345&originWidth=753&size=0&status=done&style=none&width=753)


# MySQL高级特性


todo


## 分区表


## 视图


### 物化视图


## 绑定变量 `Prepared Statement`


# 复制


MySQL内建的复制功能时构建基于MySQL的大规模、高性能、高可用应用的基础，这类应用使用的架构称为"水平扩展"。


复制解决的基本问题是让一台服务器的数据与其他服务器保持同步。一台**主库**的数据可以同步到多台**备库**上，备库本身也可以被配置成另外一台服务器的主库。主备库之间可以有多种不同的组合方式。这些内容在接下来的章节都会逐一分析。


MySQL支持两种数据的复制方式，分别为基于行的复制和基于语句的复制，实际上MySQL会混用这两种方法。这两种方式都是通过在主库上记录二进制日志，在备库重放日志的方式来实现的异步数据复制。这意味着，在同一时间点，主备库上的数据可能不一致，并且无法保证主备之间的延迟，一些大型语句可能导致备库产生几秒、几分钟甚至几小时的延迟。


复制通常不会增加主库开销，增加开销主要是启用二进制日志带来的开销，但是处于备份和崩溃恢复的目的，这个开销也是必要的。


## 复制解决的问题


- 数据分布
保持多个地理位置访问的低延迟。
- 负载均衡
通过MySQL复制可以将读操作分布到多个服务器上，实现对读密集型应用的优化，也就是读写分离。需要注意的是使用备库并不能扩展写操作，写操作始终要在主库上进行。
- 备份
虽然备库一定程度上由备份作用，但是复制不能完全取代备份的功能。
- 高可用性和故障切换
避免单点失败，包含复制的设计可以很好的切换主备库，缩短宕机时间。



## 复制原理


从宏观角度来看，复制主要有三个步骤：


1. 主库写入二进制日志
在事务的章节已经提过，在每次准备提交事务完成数据更新前，主库将数据更新的事件记录到二进制日志中。MySQL会按事务提交的顺序而非每条语句的执行顺序来记录二进制日志。在记录二进制日之后，主库会告诉存储引擎可以提交事务了。
1. 备库将二进制日志复制到自己的中继日志(Relay Log)中
备库上的IO线程会与主库建立一个客户端连接，然后在主库上启动一个特殊的**二进制转储(binlog dump)线程**，这个二进制转储线程会读取主库上二进制日志中的文件。在无新数据时会进入睡眠状态，有新数据时会被唤醒。
如果备库与主库的延迟很大，备库的IO线程可能会写很多中继日志文件，SQL线程再重放完一个中继日志事件后会尽快将其删除。但如果延迟非常严重，IO线程可能会把整个磁盘撑满。解决方法是配置`relay_log_space_limit`变量。如果所有中继日志大小之和超过这个值，IO线程会停止，等待SQL线程释放磁盘空间。但是除非磁盘空间真的紧张，否则不推荐使用这个配置项。
1. 备库的SQL线程读取中继日志中的事件，将其重放到备库数据上；此过程可以选择是否将事件写入自己的二进制日志中



![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690273-cfb85d56-48a7-436e-a241-3e9e3287ac3d.png#align=left&display=inline&height=272&margin=%5Bobject%20Object%5D&originHeight=272&originWidth=410&size=0&status=done&style=none&width=410)


需要注意的一点是，这种架构有一定的限制：在主库上并发执行的事务在备库只能串行化执行，因为只有一个SQL线程来重放中继日志中的事件。


### 基于语句的复制


基于语句的复制模式下，主库会记录那些造成数据更改的查询，当备库读取并重放这些事件时，实际上就是把主库上执行的SQL再执行了一遍。这样的好处和缺点都很明显：


优点：


- 实现简单
- 节约传输带宽（某些情况下语句占用的空间比行数据小得多）



缺点：


- 除了数据表中已有的信息，语句很可能还依赖了一些元数据（时间戳等），或是`CURRENT_USER()`一类函数
- 存储过程和触发器在使用基于语句复制模式时也可能存在问题
- 更新只能是串行的



### 基于行的复制


基于行复制的模式会将实际数据记录在二进制日志中（这是和大部分数据库选择的方案类似）。理论上基于行的复制模式整体上更优，并且在实际应用中也适用于大多数场景。


其优缺点如下：


优点:


- 可以正确的复制每一行，几乎没有行复制不能处理的场景
- 避免了锁争用，因为它直接更新数据行
- 由于无需执行SQL语句，避免了大量计算，可以更高效地复制数据。例如复制一些统计表结果时



缺点：


- 由于需要记录具体的行变更，占用空间较大。例如全表更新
- 无法处理修改表结构一类的情况，而基于语句的日志可以



## 初始化备库


需要三个条件使备库初始化，并保持主库和备库保持同步：


1. 在某个时间点的主库的数据快照
1. 主库当前的二进制日志文件、快照所处时刻二进制日志文件中的偏移量。这两个值合称为日志文件坐标（log file coordinates）
1. 从快照时间到现在的二进制日志



## 复制过滤器


可以在复制时通过过滤器过滤服务器以上一部分数据，有两种过滤方式:


- 在主库上过滤记录到二进制日志中的事件
- 在备库上过滤记录到中继日志的事件



但复制过滤随时可能会发生问题，除非万不得已，不要使用过滤。


## 复制拓扑


复制的拓扑结构可以很复杂，但要遵循如下几个基本原则:


- 一个备库只能有一个主库
- 每个备库的服务器ID唯一
- 一个主库可以有多个备库



### 一主多备


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690454-33413f3a-ceae-4b07-b65e-d9171d424c8f.png#align=left&display=inline&height=193&margin=%5Bobject%20Object%5D&originHeight=193&originWidth=233&size=0&status=done&style=none&width=233)


这种拓扑结构简单但使用，适合读多写少的情况，可以适用于如下用途:


- 为不同的用途使用不同的备库（例如添加不同的索引或使用不同的存储引擎）
- 使用备库作为容灾手段
- 使用备库作为开发、测试服务器



### 主主复制


#### 主动-主动模式


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690294-a4cc1b66-7029-4ec7-8d5f-41f7f2115748.png#align=left&display=inline&height=93&margin=%5Bobject%20Object%5D&originHeight=93&originWidth=189&size=0&status=done&style=none&width=189)


这种配置最大的问题时解决两台可写服务器产生的冲突，例如`AUTO_INCREMENT`、两主库修改了同一行记录。


不推荐使用改模式。


#### 主动-被动模式


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690269-d00d867e-72a9-4554-967e-88700eea915c.png#align=left&display=inline&height=92&margin=%5Bobject%20Object%5D&originHeight=92&originWidth=179&size=0&status=done&style=none&width=179)


这种模式和“主动-主动模式”最大的区别在于其中的一台服务器是只读的被动服务器。但是双方都配置对方为自己的主库。这个模式的意义类似于创建了一个“热备份”，用来备份、维护切换、升级等操作。


### 主库-分发主库-备库


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690264-8b18fb8a-122a-4e87-b66e-41ad4e384731.png#align=left&display=inline&height=290&margin=%5Bobject%20Object%5D&originHeight=290&originWidth=230&size=0&status=done&style=none&width=230)


每个备库都会在主库上创建一个线程执行`binlog dump`命令，他们不会共享`binlog dump`的资源，这会导致主库负载过大。


因此，如果需要多个备库，可以使用一个中间的分发主库，这个分发主库实际上是真正主库的备库，可以使用blackhole引擎。这个存储引擎不存储真正的数据表而只保存二进制日志，但是这个存储引擎可能有一些小BUG（不写入自增ID），使用时候要注意。


但是使用分发主库会导致备库与真实主库的二进制日志坐标不一致。


### 金字塔


![](https://cdn.nlark.com/yuque/0/2019/png/657413/1577093690437-7d42005a-3d1b-44b7-ba38-03dfb1fa3a13.png#align=left&display=inline&height=294&margin=%5Bobject%20Object%5D&originHeight=294&originWidth=342&size=0&status=done&style=none&width=342)


多层结构，中间备库类似与分发主库。但是中间层次越多，处理故障会更困难，不建议使用过于复杂的拓扑结构。
