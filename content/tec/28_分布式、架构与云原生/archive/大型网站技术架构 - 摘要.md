# Ref


- 《大型网站技术架构》的批注与划线，在豆瓣阅读书店查看：[https://read.douban.com/ebook/35648299/](https://read.douban.com/ebook/35648299/)



# 个人记录


## 反思


这本书出版于2013年，我于2019年6月读完，这其实是一个选书错误。虽然本书内容质量还不错，但是有些近年来的架构设计要点并未提及，设计思想也有一定的滞后，这在之后的选书阶段要多加注意，尽量读较新的技术书籍。


## 学到的东西


我通过这本书体系化的了解到了架构设计的要点。本书不涉及到代码细节，只是高屋建瓴地提到了用到地种种技术、解决的问题等。其实本书提到地很多东西我都有了解，但不成体系，通过这本书我很好地把它们串起来了。至于具体的技术细节，我主要学到的是这些：


- 一致性哈希
- 负载均衡的几种实现方法
- 网站性能优化的一些思路（静态化、缓存）



# 序章


## 好评袭来


> 本书从网站的**架构设计、快速开发、高效部署、业务监控、服务治理、运维管理**等多个角度描述了架构设计的相关重点，涉及的核心技术包括**前端优化、CDN、反向代理、缓存、消息队列、分布式存储、分布式服务、NoSQL存储、搜索、监控、安全**等一系列保证大型网站安全可靠运行的关键技术点。



## 推荐序一


> 书中的技术内容基本都从**为什么（Why）**要这么做和如何去**做（How）**两个层面进行表述。



## 推荐序二


> 本书从**性能、可用性、伸缩性、扩展性、安全性**几个网站核心架构要素切入，全面地介绍了这些核心要素面临的问题域、理论基础及应对方案



# 1 大型网站架构演化


## 1.2　大型网站架构演化发展历程


> 网站使用的缓存可以分为两种：缓存在应用服务器上的**本地缓存**和缓存在专门的**分布式缓存服务器**上的远程缓存。本地缓存的访问速度更快一些，但是受应用服务器内存限制，其缓存数据量有限，而且会出现和应用程序争用内存的情况。远程分布式缓存可以使用集群的方式，部署大内存的服务器作为专门的缓存服务器，可以在理论上做到不受内存容量限制的缓存服务，如图1.3所示。



> 使用集群是网站解决高并发、海量数据问题的常用手段。当一台服务器的处理能力、存储空间不足时，不要企图去换更强大的服务器，对大型网站而言，不管多么强大的服务器，都满足不了网站持续增长的业务需求。



> 通过负载均衡调度服务器，可将来自用户浏览器的访问请求分发到应用服务器集群中的任何一台服务器上，如果有更多的用户，就在集群中加入更多的应用服务器，使应用服务器的负载压力不再成为整个网站的瓶颈



> 应用服务器在写数据的时候，访问主数据库，主数据库通过主从复制机制将数据更新同步到从数据库，这样当应用服务器读数据的时候，就可以通过从数据库获得数据。为了便于应用程序访问读写分离后的数据库，通常在应用服务器端使用专门的数据访问模块，使数据库读写分离对应用透明。



### 1.2.6　使用反向代理和CDN加速网站响应


> CDN和反向代理的基本原理都是缓存，区别在于CDN部署在网络提供商的机房，使用户在请求网站服务时，可以从距离自己最近的网络提供商机房获取数据；而反向代理则部署在网站的中心机房，当用户请求到达中心机房后，首先访问的服务器是反向代理服务器，如果反向代理服务器中缓存着用户请求的资源，就将其直接返回给用户。



> 分布式数据库是网站数据库拆分的最后手段，只有在单表数据规模非常庞大的时候才使用。不到不得已时，网站更常用的数据库拆分手段是业务分库，将不同业务的数据库部署在不同的物理服务器上。



> NoSQL和搜索引擎都是源自互联网的技术手段，对可伸缩的分布式特性具有更好的支持。**应用服务器则通过一个统一数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。**



## 1.3　大型网站架构演化的价值观


> 网站的价值在于它能为用户提供什么价值，在于网站能做什么，而不在于它是怎么做的，所以在网站还很小的时候就去追求网站的架构是舍本逐末，得不偿失的。小型网站最需要做的就是为用户提供好的服务来创造价值，得到用户的认可，活下去，野蛮生长



> 创新的业务发展模式对网站架构逐步提出更高要求，才使得创新的网站架构得以发展成熟。**是业务成就了技术，是事业成就了人，而不是相反**。所以网站架构师应该对成就自己技术成绩的网站事业心存感恩，并努力提高技术回馈业务，才能在快速发展的互联网领域保持持续进步。



## 1.4　网站架构设计误区


> 1.4.2　为了技术而技术
> 网站技术是为业务而存在的，除此毫无意义。在技术选型和架构设计中，脱离网站业务发展的实际，一味追求时髦的新技术，可能会将网站技术发展引入崎岖小道，架构之路越走越难。



# 2 大型网站架构模式


## 2.1　网站架构模式


> 在网站的发展过程中，分层结构对网站支持高并发向分布式方向发展至关重要。因此在网站规模还很小的时候就应该采用分层的架构，这样将来网站做大时才能有更好地应对。



> 如果说分层是将软件在横向方面进行切分，那么分割就是在纵向方面对软件进行切分。



> 在网站应用中，常用的分布式方案有以下几种。



> 分布式计算：严格说来，应用、服务、实时数据处理都是计算，网站除了要处理这些在线业务，还有很大一部分用户没有直观感受的后台业务要处理，包括搜索引擎的索引构建、数据仓库的数据分析统计等。这些业务的计算规模非常庞大，**目前网站普遍使用Hadoop及其MapReduce分布式计算框架进行此类批处理计算，其特点是移动计算而不是移动数据，将计算程序分发到数据所在的位置以加速计算和分布式计算。**



> 对于用户访问集中的模块（比如网站的首页），还需要将独立部署的服务器集群化，即多台服务器部署相同应用构成一个集群，通过负载均衡设备共同对外提供服务



> 大型网站架构设计在很多方面都使用了缓存设计。
> CDN：即内容分发网络，部署在距离终端用户最近的网络服务商，用户的网络请求总是先到达他的网络服务商那里，在这里缓存网站的一些静态资源（较少变化的数据），可以就近以最快速度返回给用户，如视频网站和门户网站会将用户访问量大的热点内容缓存在CDN。
> 反向代理：反向代理属于网站前端架构的一部分，部署在网站的前端，当用户请求到达网站的数据中心时，最先访问到的就是反向代理服务器，这里缓存网站的静态资源，无需将请求继续转发给应用服务器就能返回给用户。
> 本地缓存：在应用服务器本地缓存着热点数据，应用程序可以在本机内存中直接访问数据，而无需访问数据库。
> 分布式缓存：大型网站的数据量非常庞大，即使只缓存一小部分，需要的内存空间也不是单机能承受的，所以除了本地缓存，还需要分布式缓存，将数据缓存在一个专门的分布式缓存集群中，应用程序通过网络通信访问缓存数据。



> **大型网站架构中，系统解耦合的手段除了前面提到的分层、分割、分布等，还有一个重要手段是异步**，业务之间的消息传递不是同步调用，而是将一个业务操作分成多个阶段，每个阶段之间通过共享数据的方式异步执行进行协作。



> 为了抵御地震、海啸等不可抗力导致的网站完全瘫痪，某些大型网站会对整个数据中心进行备份，全球范围内部署灾备数据中心。网站程序和数据实时同步到多个灾备数据中心。



> 目前大型网站的自动化架构设计主要集中在发布运维方面。



> 发布对网站都是头等大事，许多网站故障出在发布环节，网站工程师经常加班也是因为发布不顺利。通过减少人为干预，使**发布过程自动化**可有效减少故障。发布过程包括诸多环节。自动化代码管理，代码版本控制、代码分支创建合并等过程自动化，开发工程师只要提交自己参与开发的产品代号，系统就会自动为其创建开发分支，后期会自动进行代码合并；**自动化测试**，代码开发完成，提交测试后，系统自动将代码部署到测试环境，启动自动化测试用例进行测试，向相关人员发送测试报告，向系统反馈测试结果；**自动化安全检测**，安全检测工具通过对代码进行静态安全扫描及部署到安全测试环境进行安全攻击测试，评估其安全性；最后进行**自动化部署**，将工程代码自动部署到线上生产环境。
> 此外，网站在运行过程中可能会遇到各种问题：服务器宕机、程序Bug、存储空间不足、突然爆发的访问高峰。网站需要对线上生产环境进行**自动化监控**，对服务器进行心跳检测，并监控其各项性能指标和应用程序的关键数据指标。如果发现异常、超出预设的阈值，就进行自动化报警，向相关人员发送报警信息，警告故障可能会发生。在检测到故障发生后，系统会进行**自动化失效转移**，将失效的服务器从集群中隔离出去，不再处理系统中的应用请求。待故障消除后，系统进行自动化失效恢复，重新启动服务，同步数据保证数据的一致性。在网站遇到访问高峰，超出网站最大处理能力时，为了保证整个网站的安全可用，还会进行**自动化降级**，通过拒绝部分请求及关闭部分不重要的服务将系统负载降至一个安全的水平，必要时，还需要**自动化分配资源**，将空闲资源分配给重要的服务，扩大其部署规模。



## 2.2　架构模式在新浪微博的应用


> 这些被分层和分割后的业务模块与基础技术模块分布式部署，每个模块都部署在一组独立的服务器集群上，通过远程调用的方式进行依赖访问



# 3　大型网站核心架构要素


> 一般说来，除了当前的系统功能需求外，软件架构还需要关注**性能、可用性、伸缩性、扩展性和安全性**这5个架构要素，架构设计过程中需要平衡这5个要素之间的关系以实现需求和架构目标，也可以通过考察这些架构要素来衡量一个软件架构设计的优劣，判断其是否满足期望。



## 3.1 性能


> 衡量网站性能有一系列指标，重要的有**响应时间、TPS、系统性能计数器**等，通过测试这些指标以确定系统设计是否达到目标。



## 3.2 可用性


> **网站高可用的主要手段是冗余**，应用部署在多台服务器上同时提供访问，数据存储在多台服务器上互相备份，任何一台服务器宕机都不会影响应用的整体可用，也不会导致数据丢失。



## 3.3 伸缩性


> 对于缓存服务器集群，加入新的服务器可能会导致缓存路由失效，进而导致集群中大部分缓存数据都无法访问。



> 关系数据库虽然支持数据复制，主从热备等机制，但是很难做到大规模集群的可伸缩性，因此关系数据库的集群伸缩性方案必须在数据库之外实现，通过路由分区等手段将部署有多个数据库的服务器组成一个集群。



## 3.4 扩展性


> 衡量网站架构扩展性好坏的主要标准就是在网站增加新的业务产品时，是否可以实现对现有产品透明无影响，不需要任何改动或者很少改动既有业务功能就可以上线新产品。不同产品之间是否很少耦合，一个产品改动对其他产品无影响，其他产品和功能不需要受牵连进行改动。



> **网站可伸缩架构的主要手段是事件驱动架构和分布式服务。**

**
## 3.5 安全性
**
## 3.6 小结


> 伸缩性、扩展性



伸缩性指的是系统处理增长的并发请求的能力；而扩展性指的是系统架构对于新需求的扩展能力。


# 4 瞬时响应：网站的高性能架构


## 4.1 网站性能测试


### 4.1.1 不同视角下的网站性能


#### 2．开发人员视角的网站性能


> 开发人员关注的主要是应用程序本身及其相关子系统的性能，包括**响应延迟、系统吞吐量、并发处理能力、系统稳定性**等技术指标。**主要的优化手段有使用缓存加速数据读取，使用集群提高吞吐能力，使用异步消息加快请求响应及实现削峰**，使用代码优化手段改善程序性能。



### 4.1.2 性能测试指标


#### 1．响应时间


> 指应用执行一个操作需要的时间，包括从发出请求开始到收到最后响应数据所需要的时间。响应时间是系统最重要的性能指标



> 实践中通常采用的办法是重复请求，比如一个请求操作重复执行一万次，测试一万次执行需要的总响应时间之和，然后除以一万，得到单次请求的响应时间。



#### 2．并发数


> 在网站产品设计初期，产品经理和运营人员就需要规划不同发展阶段的网站系统用户数，并以此为基础，根据产品特性和运营手段，推算在线用户数和并发用户数。这些指标将成为系统非功能设计的重要依据。



#### 3．吞吐量


> TPS（每秒事务数）是吞吐量的一个常用量化指标，此外还有HPS（每秒HTTP请求数）、QPS（每秒查询数）等。
> **在系统并发数由小逐渐增大的过程中（这个过程也伴随着服务器系统资源消耗逐渐增大），系统吞吐量先是逐渐增加，达到一个极限后，随着并发数的增加反而下降，达到系统崩溃点后，系统资源耗尽，吞吐量为零。**



注意区分吞吐量与并发量


#### 4．性能计数器


> 在Linux系统中使用top命令查看，该值是三个浮点数，表示最近1分钟，10分钟，15分钟的运行队列平均进程数



> 压力测试
> 超过安全负载的情况下，对系统继续施加压力，直到系统崩溃或不能再处理任何请求，以此获得系统最大压力承受能力。



> 稳定性测试
> 被测试系统在特定硬件、软件、网络环境条件下，给系统加载一定业务压力，使系统运行一段较长时间，以此检测系统是否稳定。在不同生产环境、不同时间点的请求压力是不均匀的，呈波浪特性，因此为了更好地模拟生产环境，稳定性测试也应不均匀地对系统施加压力。



> 图4.3中的横坐标表示消耗的系统资源，纵坐标表示系统处理能力（吞吐量）。在开始阶段，随着并发请求数目的增加，系统使用较少的资源就达到较好的处理能力（a～b段），这一段是网站的日常运行区间，网站的绝大部分访问负载压力都集中在这一段区间，被称作**性能测试，测试目标是评估系统性能是否符合需求及设计目标**；随着压力的持续增加，系统处理能力增加变缓，直到达到一个最大值（c点），这是系统的最大负载点，这一段被称作**负载测试。测试目标是评估当系统因为突发事件超出日常访问压力的情况下，保证系统正常运行情况下能够承受的最大访问负载压力**；超过这个点后，再增加压力，系统的处理能力反而下降，而资源消耗却更多，直到资源消耗达到极限（d点），这个点可以看作是系统的崩溃点，超过这个点继续加大并发请求数目，系统不能再处理任何请求，这一段被称作**压力测试，测试目标是评估可能导致系统崩溃的最大访问负载压力**。



![屏幕快照 2019-12-22 上午12.20.17.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1576945417332-a174f8c0-67ae-49a4-96af-aa3096c20d84.png#align=left&display=inline&height=379&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-12-22%20%E4%B8%8A%E5%8D%8812.20.17.png&originHeight=794&originWidth=1562&size=207687&status=done&style=stroke&width=746)
![屏幕快照 2019-12-22 上午12.28.08.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1576945794143-996b44d3-8163-4c96-aaae-93be3db407f7.png#align=left&display=inline&height=374&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-12-22%20%E4%B8%8A%E5%8D%8812.28.08.png&originHeight=782&originWidth=1558&size=228505&status=done&style=stroke&width=746)


> 4.1.4　性能测试报告
> 测试结果报告应能够反映上述性能测试曲线的规律，阅读者可以得到系统性能是否满足设计目标和业务要求、系统最大负载能力、系统最大压力承受能力等重要信息，表4.2是一个简单示例



![屏幕快照 2019-12-22 上午12.30.49.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1576945965120-ea513e75-d203-4388-8c41-226c4c3f6cc7.png#align=left&display=inline&height=280&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-12-22%20%E4%B8%8A%E5%8D%8812.30.49.png&originHeight=420&originWidth=1120&size=284504&status=done&style=none&width=746)


上图中的并发数一列中的 800、1000、1200、2000 实际上是对应的响应时间，此处是电子版错误。




### 4.1.5 性能优化策略


#### 2．性能优化


> 根据网站分层架构，可分为Web前端性能优化、应用服务器性能优化、存储服务器性能优化3大类。



## 4.2 Web 前端性能优化


#### 1．减少http请求


> 减少HTTP的主要手段是合并CSS、合并JavaScript、合并图片。将浏览器一次访问需要的JavaScript、CSS合并成一个文件，这样浏览器就只需要一次请求



#### 2．使用浏览器缓存


> 比如需要更新10个图标文件，不宜把10个文件一次全部更新，而是应一个文件一个文件逐步更新，并有一定的间隔时间，以免用户浏览器突然大量缓存失效，集中更新缓存，造成服务器负载骤增、网络堵塞的情况。



#### 5．减少Cookie传输


> 由于CDN部署在网络运营商的机房，这些运营商又是终端用户的网络服务提供商，因此用户请求路由的第一跳就到达了CDN服务器，当CDN中存在浏览器请求的资源时，从CDN直接返回给浏览器，最短路径返回响应，加快用户访问速度，减少数据中心负载压力。
> CDN能够缓存的一般是静态资源，如图片、文件、CSS、Script脚本、静态网页等，但是这些文件访问频度很高，将其缓存在CDN可极大改善网页的打开速度。



> 传统代理服务器位于浏览器一侧，代理浏览器将HTTP请求发送到互联网上，而反向代理服务器位于网站机房一侧，代理网站Web服务器接收HTTP请求。



## 4.3　应用服务器性能优化


> **网站性能优化第一定律：优先考虑使用缓存优化性能。**



### 4.3.1 分布式缓存


#### 2．合理使用缓存


> 缓存是为提高数据读取性能的，缓存数据丢失或者缓存不可用不会影响到应用程序的处理——它可以从数据库直接获取数据。但是随着业务的发展，缓存会承担大部分数据访问的压力，数据库已经习惯了有缓存的日子，所以**当缓存服务崩溃时，数据库会因为完全不能承受如此大的压力而宕机，进而导致整个网站不可用。这种情况被称作缓存雪崩**，发生这种故障，甚至不能简单地重启缓存服务器和数据库服务器来恢复网站访问。



> **缓存穿透**
> **如果因为不恰当的业务、或者恶意攻击持续高并发地请求某个不存在的数据，由于缓存没有保存该数据，所有的请求都会落到数据库上，会对数据库造成很大压力，甚至崩溃。一个简单的对策是将不存在的数据也缓存起来（其value值为null）。**



区分缓存雪崩、缓存穿透。


#### 3．分布式缓存架构


> 应用程序通过**一致性Hash**等路由算法选择缓存服务器远程访问缓存数据，缓存服务器之间不通信，缓存集群的规模可以很容易地实现扩容，具有良好的可伸缩性。



#### 4．Memcached


> 而其客户端路由算法一致性Hash更成为数据存储伸缩性架构设计的经典范式（参考本书第6章）。事实上，**正是集群内服务器互不通信使得集群可以做到几乎无限制的线性伸缩，这也正是目前流行的许多大数据技术的基本架构特点。**



> 消息队列具有很好的削峰作用——即通过异步处理，将短时间高并发产生的事务消息存储在消息队列中，从而削平高峰期的并发事务。



> 需要注意的是，由于数据写入消息队列后立即返回给用户，数据在后续的业务校验、写数据库等操作可能失败，因此在使用消息队列进行业务异步处理后，需要适当修改业务流程进行配合，



### 4.3.4 代码优化


#### 1．多线程


> **从资源利用的角度看，使用多线程的原因主要有两个：IO阻塞与多CPU。**



> 对网站而言，不管有没有进行多线程编程，工程师写的每一行代码都会被多线程执行，因为用户请求是并发提交的，也就是说，所有的资源——对象、内存、文件、数据库，乃至另一个线程都可能被多线程并发访问。



#### 2．资源复用


> 系统运行时，要尽量减少那些开销很大的系统资源的创建和销毁，比如数据库连接、网络通信连接、线程、复杂对象等。从编程角度，资源复用主要有两种模式：单例（Singleton）和对象池（Object Pool）



#### 4．垃圾回收


> 事实上，某些Web应用在整个运行期间可以做到从不进行Full GC。



## 4.4　存储性能优化


### 4.4.2 B+树 VS LSM树
> 目前数据库多采用两级索引的B＋树，树的层次最多三层。因此可能需要5次磁盘访问才能更新一条记录（三次磁盘访问获得数据索引及行ID，然后再进行一次数据文件读操作及一次数据文件写操作）。



> 目前许多NoSQL产品采用LSM树作为主要数据结构，如图4.21所示



LSM 全称 Log Structured Merge Trees，来自于 Google 奠基论文 Big Table。我认为 InnoDB 引擎的插入缓冲、修改缓冲和 LSM 的思想是一样的。

![屏幕快照 2019-12-22 下午2.15.41.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1576995493177-48124a12-e049-4d82-8303-cbd50385e7aa.png#align=left&display=inline&height=652&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-12-22%20%E4%B8%8B%E5%8D%882.15.41.png&originHeight=652&originWidth=1558&size=512155&status=done&style=none&width=1558)


> LSM树可以看作是一个N阶合并树。数据写操作（包括插入、修改、删除）都在内存中进行，并且都会创建一个新记录（修改会记录新的数据值，而删除会记录一个删除标志），这些数据在内存中仍然还是一棵排序树，当数据量超过设定的内存阈值后，会将这棵排序树和磁盘上最新的排序树合并。当这棵排序树的数据量也超过设定阈值后，和磁盘上下一级的排序树合并



> 在需要进行读操作时，总是从内存中的排序树开始搜索，如果没有找到，就从磁盘上的排序树顺序查找。



> 在LSM树上进行一次数据更新不需要磁盘访问，在内存即可完成，速度远快于B＋树。当数据访问以写操作为主，而读操作则集中在最近写入的数据上时，使用LSM树可以极大程度地减少磁盘的访问次数，加快访问速度。



### 4.4.3 RAID 与 HDFS


> 在HDFS中有两种重要的服务器角色：NameNode（名字服务节点）和DataNode（数据存储节点）。NameNode在整个HDFS中只部署一个实例，提供元数据服务，相当于操作系统中的文件分配表（FAT），管理文件名Block的分配，维护整个文件系统的目录树结构。DataNode则部署在HDFS集群中其他所有服务器上，提供真正的数据存储服务。



> 应用程序（Client）需要写文件时，首先访问NameNode，请求分配数据块，NameNode根据管理的DataNode服务器的磁盘空间，按照一定的负载均衡策略，分配若干数据块供Client使用。



## 4.5　小结


> 网站性能对最终用户而言是一种主观感受，性能优化的最终目的就是改善用户的体验，使他们感觉网站很快。离开这个目的，追求技术上的所谓高性能，是舍本逐末，没有多大意义。而用**户体验的快或是慢，可以通过技术手段改善，也可以通过优化交互体验改善。**



# 5 万无一失：网站的高可用架构


## 5.1　网站可用性的度量与考核


> 可用性指标是网站架构设计的重要指标，对外是服务承诺，对内是考核指标。从管理层面，可用性指标是网站或者产品的整体考核指标，具体到每个工程师的考核，更多的是使用故障分。
> 所谓故障分是指对网站故障进行分类加权计算故障责任的方法。



## 5.3　高可用的应用


> 所谓无状态的应用是指应用服务器不保存业务的上下文信息，而仅根据每次请求提交的数据进行相应的业务逻辑处理，多个服务实例（服务器）之间完全对等，请求提交到任意服务器，处理结果都是完全一样的。



### 5.3.2．Session绑定


> 会话黏滞



### 5.3.4．Session服务器


> 那么有没有可用性高、伸缩性好、性能也不错，对信息大小又没有限制的服务器集群Session管理方案呢？
> 答案就是Session服务器。利用独立部署的Session服务器（集群）统一管理Session，应用服务器每次读写Session时，都访问Session服务器，如图5.9所示。



> 这种解决方案事实上是将应用服务器的状态分离，分为无状态的应用服务器和有状态的Session服务器，然后针对这两种服务器的不同特性分别设计其架构。



> 单点登录（SSO）



## 5.4　高可用的服务


> 可复用的服务模块为业务产品提供基础公共服务，大型网站中这些服务通常都独立分布式部署，被具体应用远程调用。可复用的服务和应用一样，也是无状态的服务，因此可以使用类似负载均衡的失效转移策略实现高可用的服务。



> 具体实践中，还有以下几点高可用的服务策略。
> 

> 1．分级管理
> 运维上将服务器进行分级管理，核心应用和服务优先使用更好的硬件，在运维响应速度上也格外迅速。显然，用户及时付款购物比能不能评价商品更重要，所以订单、支付服务比评价服务有更高优先级。
> 同时在服务部署上也进行必要的隔离，避免故障的连锁反应。低优先级的服务通过启动不同的线程或者部署在不同的虚拟机上进行隔离，而高优先级的服务则需要部署在不同的物理机上，核心服务和数据甚至需要部署在不同地域的数据中心。
> 

> 2．超时设置
> 由于服务端宕机、线程死锁等原因，可能导致应用程序对服务端的调用失去响应，进而导致用户请求长时间得不到响应，同时还占用应用程序的资源，不利于及时将访问请求转移到正常的服务器上。
> 在应用程序中设置服务调用的超时时间，**一旦超时，通信框架就抛出异常**，应用程序根据服务调度策略，可选择继续重试或将请求转移到提供相同服务的其他服务器上。
> 

> 3．异步调用
> 

> 4．服务降级
> 拒绝服务：拒绝低优先级应用的调用，减少服务调用并发数，确保核心应用正常使用；或者随机拒绝部分请求调用，节约资源，让另一部分请求得以成功，避免要死大家一起死的惨剧。
> 关闭功能：关闭部分不重要的服务，或者服务内部关闭部分不重要的功能，以节约系统开销，为重要的服务和功能让出资源。淘宝在每年的“双十一”促销中就使用这种方法，在系统最繁忙的时段关闭“评价”、“确认收货”等非核心服务，以保证核心交易服务的顺利完成。
> > 

5．幂等性设计> 服务重复调用是无法避免的，应用层也不需要关心服务是否真的失败，只要没有收到调用成功的响应，就可以认为调用失败，并重试服务调用。因此必须在服务层保证服务重复调用和调用一次产生的结果相同，即服务具有幂等性。
> 有些服务天然具有幂等性，比如将用户性别设置为男性，不管设置多少次，结果都一样。但是对于转账交易等操作，问题就会比较复杂，需要通过交易编号等信息进行服务调用有效性校验，只有有效的操作才能继续执行。



## 5.5　高可用的数据


> CAP原理认为，一个提供数据服务的存储系统无法同时满足数据一致性（Consistency）、数据可用性（Availibility）、分区耐受性（Patition Tolerance，系统具有跨网络分区的伸缩性）这三个条件，如图5.10所示。



> 所以在大型网站中，通常会选择强化分布式存储系统的可用性（A）和伸缩性（P），而在某种程度上放弃一致性（C）。



> 需求，企图打造一个完美的产品，可能会使设计进入两难境地，难以为继。
> 具体说来，数据一致性又可分为如下几点。
> **数据强一致**
> 各个副本的数据在物理存储中总是一致的；数据更新操作结果和操作响应总是一致的，即操作响应通知更新失败，那么数据一定没有被更新，而不是处于不确定状态。
> **数据用户一致**
> 即数据在物理存储中的各个副本的数据可能是不一致的，但是终端用户访问时，通过纠错和校验机制，可以确定一个一致的且正确的数据返回给用户。
> **数据最终一致**
> 这是数据一致性中较弱的一种，即物理存储的数据可能是不一致的，终端用户访问到的数据可能也是不一致的（同一用户连续访问，结果不同；或者不同用户同时访问，结果不同），但系统经过一段时间（通常是一个比较短的时间段）的自我恢复和修正，数据最终会达到一致。



> 传统的企业级关系数据库系统几乎都提供了数据实时同步备份的机制。而一开始就为大型网站而设计的各种NoSQL数据库（如HBase）更是将数据备份机制作为产品最主要的功能点之一。
> 关系数据库热备机制就是通常所说的Master-Slave同步机制。Master-Slave机制不但解决了数据备份问题，还改善了数据库系统的性能，实践中，通常使用读写分离的方法访问Slave和Master数据库，写操作只访问Master数据库，读操作只访问Slave数据库。



> 5.5.3　失效转移
> 若数据服务器集群中任何一台服务器宕机，那么应用程序针对这台服务器的所有读写操作都需要重新路由到其他服务器，保证数据访问不会失败，这个过程叫作失效转移。
> 失效转移操作由三部分组成：失效确认、访问转移、数据恢复。



> **系统确认一台服务器是否宕机的手段有两种：心跳检测和应用程序访问失败报告，**



## 5.6　高可用网站的软件质量保证


> 因此在网站发布时，并不是把测试通过的代码包直接发布到线上服务器，而是先发布到预发布机器上，开发工程师和测试工程师在预发布服务器上进行预发布验证，执行一些典型的业务流程，确认系统没有问题后才正式发布。
> 预发布服务器是一种特殊用途的服务器，它和线上的正式服务器唯一的不同就是没有配置在负载均衡服务器上，外部用户无法访问



## 5.7　网站运行监控


> 5.7.1　监控数据采集
> 广义上的网站监控涵盖所有非直接业务行为的数据采集与管理，包括供数据分析师和产品设计师使用的网站用户行为日志、业务运行数据，以及供运维工程师和开发工程师使用的系统性能数据等。



#### 1．用户行为日志收集


> 用户行为日志指用户在浏览器上所做的所有操作及其所在的操作环境，包括用户操作系统与浏览器版本信息，IP地址、页面访问路径、页面停留时间等，这些数据对统计网站PV/UV指标、分析用户行为、优化网站设计、个性化营销与推荐等非常重要。



#### 2．服务器性能监控


> 收集服务器性能指标，如系统Load、内存占用、磁盘IO、网络IO等对尽早做出故障预警，及时判断应用状况，防患于未然，将故障扼杀在萌芽时期非常重要。



#### 3．运行数据报告


> 失效转移
> 除了应用程序访问失败时进行失效转移，监控系统还可以在发现故障的情况下主动通知应用，进行失效转移。
> 自动优雅降级
> 优雅降级是指网站为了应付突然爆发的访问高峰，主动关闭部分功能，释放部分系统资源，保证网站核心功能正常访问的一个手段。



# 6　永无止境：网站的伸缩性架构


> 所谓网站的伸缩性是指不需要改变网站的软硬件设计，仅仅通过改变部署的服务器数量就可以扩大或者缩小网站的服务处理能力。



## 6.1　网站架构的伸缩性设计


> 一般说来，网站的伸缩性设计可分成两类，一类是根据功能进行物理分离实现伸缩，一类是单一功能通过集群实现伸缩。前者是不同的服务器部署不同的服务，提供不同的功能；后者是集群内的多台服务器部署相同的服务，提供相同的功能。



一般情况下，是将业务先拆分为小模块，每个模块再做成集群。所以说，这两个过程是相辅相成的。


> 具体来说，集群伸缩性又可分为应用服务器集群伸缩性和数据服务器集群伸缩性。这两种集群由于对数据状态管理的不同，技术实现也有非常大的区别。而数据服务器集群也可分为缓存数据服务器集群和存储数据服务器集群，这两种集群的伸缩性设计也不大相同。



## 6.2　应用服务器集群的伸缩性设计


### HTTP 重定向负载均衡


![屏幕快照 2019-12-22 下午7.59.12.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1577016061452-ef79b758-fff4-4bb8-b35b-e605ceece381.png#align=left&display=inline&height=477&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-12-22%20%E4%B8%8B%E5%8D%887.59.12.png&originHeight=954&originWidth=1056&size=381828&status=done&style=shadow&width=528)

### DNS 域名解析负载均衡


 ![屏幕快照 2019-12-22 下午8.00.26.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1577016132278-93c453a4-fe9b-4218-80ae-5818f9d5c0d3.png#align=left&display=inline&height=472&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-12-22%20%E4%B8%8B%E5%8D%888.00.26.png&originHeight=944&originWidth=1128&size=403539&status=done&style=shadow&width=564)


> DNS域名解析负载均衡的优点是将负载均衡的工作转交给DNS，省掉了网站管理维护负载均衡服务器的麻烦，同时许多DNS还支持基于地理位置的域名解析，即会将域名解析成距离用户地理最近的一个服务器地址，这样可加快用户访问速度，改善性能。但是DNS域名解析负载均衡也有缺点，就是目前的DNS是多级解析，每一级DNS都可能缓存A记录，当下线某台服务器后，即使修改了DNS的A记录，要使其生效也需要较长时间，这段时间，DNS依然会将域名解析到已经下线的服务器，导致用户访问失败；而且DNS负载均衡的控制权在域名服务商那里，网站无法对其做更多改善和更强大的管理。
> 事实上，大型网站总是部分使用DNS域名解析，利用域名解析作为第一级负载均衡手段，即域名解析得到的一组服务器并不是实际提供Web服务的物理服务器，而是同样提供负载均衡服务的内部服务器，这组内部负载均衡服务器再进行负载均衡



### 反向代理负载均衡


![屏幕快照 2019-12-22 下午8.03.07.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1577016290591-1f2b7851-ee01-41fe-8142-520654f7e2e4.png#align=left&display=inline&height=463&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-12-22%20%E4%B8%8B%E5%8D%888.03.07.png&originHeight=926&originWidth=1190&size=312554&status=done&style=shadow&width=595)


> 由于反向代理服务器转发请求在HTTP协议层面，因此也叫**应用层负载均衡**。其优点是和反向代理服务器功能集成在一起，部署简单。缺点是反向代理服务器是所有请求和响应的中转站，其性能可能会成为瓶颈。



### IP 负载均衡


![屏幕快照 2019-12-22 下午8.03.51.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1577016347697-0a7ce457-185c-44dc-acd2-638cfb6e3171.png#align=left&display=inline&height=465&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-12-22%20%E4%B8%8B%E5%8D%888.03.51.png&originHeight=930&originWidth=1476&size=514910&status=done&style=shadow&width=738)


> IP负载均衡在内核进程完成数据分发，较反向代理负载均衡（在应用程序中分发数据）有更好的处理性能。但是由于所有请求响应都需要经过负载均衡服务器，集群的最大响应数据吞吐量不得不受制于负载均衡服务器网卡带宽。对于提供下载服务或者视频服务等需要传输大量数据的网站而言，难以满足需求。能不能让负载均衡服务器只分发请求，而使响应数据从真实物理服务器直接返回给用户呢？



### 数据链路负载均衡


![屏幕快照 2019-12-22 下午8.05.27.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1577016431506-e17f913d-48fb-4b67-9770-045b7aad13dc.png#align=left&display=inline&height=452&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-12-22%20%E4%B8%8B%E5%8D%888.05.27.png&originHeight=936&originWidth=1544&size=534188&status=done&style=shadow&width=746)


> 顾名思义，数据链路层负载均衡是指在通信协议的数据链路层修改mac地址进行负载均衡



> **这种数据传输方式又称作三角传输模式，负载均衡数据分发过程中不修改IP地址，只修改目的mac地址，通过配置真实物理服务器集群所有机器虚拟IP和负载均衡服务器IP地址一致，从而达到不修改数据包的源地址和目的地址就可以进行数据分发的目的，由于实际处理请求的真实物理服务器IP和数据请求目的IP一致，不需要通过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。这种负载均衡方式又称作直接路由方式（DR）。**



> 使用三角传输模式的链路层负载均衡是目前大型网站使用最广的一种负载均衡手段。



> 而具体的负载均衡算法通常有以下几种。

- 轮询
- 加权轮询
- 随机
- 最少连接
- 源地址散列，用于粘滞会话



## 6.3　分布式缓存集群的伸缩性设计


> 和所有服务器都部署相同应用的应用服务器集群不同，分布式缓存服务器集群中不同服务器中缓存的数据各不相同，缓存访问请求不可以在缓存服务器集群中的任意一台处理，必须先找到缓存有需要数据的服务器，然后才能访问。这个特点会严重制约分布式缓存集群的伸缩性设计，因为新上线的缓存服务器没有缓存任何数据，而已下线的缓存服务器还缓存着网站的许多热点数据。
> **必须让新上线的缓存服务器对整个分布式缓存集群影响最小**，也就是说新加入缓存服务器后应使整个缓存服务器集群中已经缓存的数据尽可能还被访问到，这是分布式缓存集群伸缩性设计的最主要目标。



一般而言，不同的key通过散列函数选取对应的缓存服务器，但是直接使用简单散列函数会产生如下明显的问题：


> 很容易就可以计算出，3台服务器扩容至4台服务器，大约有75％（3/4）被缓存了的数据不能正确命中，随着服务器集群规模的增大，这个比例线性上升。当100台服务器的集群中加入一台新服务器，不能命中的概率是99％（N/（N＋1））。



### 6.3.3　分布式缓存的一致性Hash算法


> 具体算法过程为：先构造一个长度为0~2的整数环（这个环被称作一致性Hash环），根据节点名称的Hash值（其分布范围同样为0~2）将缓存服务器节点放置在这个Hash环上。然后根据需要缓存的数据的KEY值计算得到其Hash值（其分布范围也同样为0~2），然后在Hash环上顺时针查找距离这个KEY的Hash值最近的缓存服务器节点，完成KEY到服务器的Hash映射查找



![屏幕快照 2019-12-22 下午8.29.17.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1577017866328-a910dd7f-61f3-42d4-8885-afdb23a19866.png#align=left&display=inline&height=624&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-12-22%20%E4%B8%8B%E5%8D%888.29.17.png&originHeight=1248&originWidth=1176&size=530758&status=done&style=shadow&width=588)


> 具体应用中，这个长度为2的一致性Hash环通常使用二叉查找树实现，Hash查找过程实际上是在二叉查找树中查找不小于查找数的最小数值。当然这个二叉树的最右边叶子节点和最左边的叶子节点相连接，构成环。



> 但是，上面描述的算法过程还存在一个小小的问题。
> 新加入的节点NODE3只影响了原来的节点NODE1，也就是说一部分原来需要访问NODE1的缓存数据现在需要访问NODE3（概率上是50％）。但是原来的节点NODE0和NODE2不受影响，这就意味着NODE0和NODE2缓存数据量和负载压力是NODE1与NODE3的两倍。如果4台机器的性能是一样的，那么这种结果显然不是我们需要的。
> 怎么办？



> 解决上述一致性Hash算法带来的负载不均衡问题，也可以通过使用虚拟层的手段：将每台物理缓存服务器虚拟为一组虚拟缓存服务器，将虚拟服务器的Hash值放置在Hash环上，KEY在环上先找到虚拟服务器节点，再得到物理服务器的信息。
> 这样新加入物理服务器节点时，是将一组虚拟节点加入环中，如果虚拟节点的数目足够多，这组虚拟节点将会影响同样多数目的已经在环上存在的虚拟节点，这些已经存在的虚拟节点又对应不同的物理节点。最终的结果是：新加入一台缓存服务器，将会较为均匀地影响原来集群中已经存在的所有服务器，也就是说分摊原有缓存服务器集群中所有服务器的一小部分负载，其总的影响范围和上面讨论过的相同。如图6.13所示。



## 6.4　数据存储服务器集群的伸缩性设计


> 缓存的目的是加速数据读取的速度并减轻数据存储服务器的负载压力，因此部分缓存数据的丢失不影响业务的正常处理，因为数据还可以从数据库等存储服务器上获取。
> 而数据存储服务器必须保证数据的可靠存储，任何情况下都必须保证数据的可用性和正确性。因此缓存服务器集群的伸缩性架构方案不能直接适用于数据库等存储服务器。存储服务器集群的伸缩性设计相对更复杂一些，具体说来，又可分为关系数据库集群的伸缩性设计和NoSQL数据库的伸缩性设计。



> 在大型网站的实际应用中，即使进行了分库和主从复制，对一些单表数据仍然很大的表，比如Facebook的用户数据库，淘宝的商品数据库，还需要进行分片，将一张表拆开分别存储在多个数据库中。



> 相比关系数据库本身功能上的优雅强大，目前各类分布式关系数据库解决方案都显得非常简陋，限制了关系数据库某些功能的使用。但**是当网站业务面临不停增长的海量业务数据存储压力时，又不得不利用分布式关系数据库的集群伸缩能力，这时就必须从业务上回避分布式关系数据库的各种缺点：避免事务或利用事务补偿机制代替数据库事务；分解数据访问逻辑避免JOIN操作等**



> 在计算机数据存储领域，一直是关系数据库（Relation Database）的天下，以至传统企业应用领域，许多应用系统设计都是面向数据库设计——先设计数据库然后设计程序，从而导致关系模型绑架对象模型，并由此引申出旷日持久的业务对象贫血模型与充血模型之争。



Java 中，贫血模型与充血模型的区别在于 Bean 是否只包含 get、set 方法而不包含逻辑。
贫血模型不够面向对象，但是其结构简单，只作为层与层之间的传递对象。操作 Bean 的方法单独封装为独立的模块。
充血模型将一些逻辑包含在 Bean 中，其优点在于符合面向对象思想，缺点在于逻辑放到 Bean 中还是业务逻辑中对设计有很高的要求。


> 一般而言，NoSQL数据库产品都放弃了关系数据库的两大重要基础：以关系代数为基础的结构化查询语言（SQL）和事务一致性保证（ACID）。



> HBase 调用时序如图6.20所示。



![屏幕快照 2019-12-22 下午9.21.09.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1577020984350-c492a976-ff9b-489b-a6f2-29578bf36d48.png#align=left&display=inline&height=348&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-12-22%20%E4%B8%8B%E5%8D%889.21.09.png&originHeight=696&originWidth=1484&size=238365&status=done&style=shadow&width=742)


# 7　随需应变：网站的可扩展架构


> 而据说摇一摇这个功能是两个实习生用一个星期就开发完成上线的。



？？？


> 经常听到各种场合中对扩展性和伸缩性的误用，包括许多资深网站架构师也常常混淆两者，用扩展性表示伸缩性。在此，我们澄清下这两个概念。



> 扩展性
> 它是系统架构设计层面的开闭原则（对扩展开放，对修改关闭），架构设计考虑未来功能扩展，当系统增加新功能时，不需要对现有系统的结构和代码进行修改。



## 7.1　构建可扩展的网站架构


> 笔者认为，软件架构师最大的价值不在于掌握多少先进的技术，而在于具有将一个大系统切分成N个低耦合的子模块的能力，这些子模块包含横向的业务模块，也包含纵向的基础技术模块



> 模块分布式部署以后具体聚合方式主要有分布式消息队列和分布式服务。



## 7.2　利用分布式消息队列降低系统耦合性


> 为了避免消息队列服务器宕机造成消息丢失，会将消息成功发送到消息队列的消息存储在消息生产者服务器，等消息真正被消息消费者服务器处理后才删除消息。



## 7.3　利用分布式服务打造可复用的业务平台


> 对应用最少侵入
> 网站技术是为业务服务的，是否使用分布式服务需要根据业务发展规划，分布式服务也需要渐进式的演化，甚至会出现反复，即使用了分布式服务后又退回到集中式部署，分布式服务框架需要支持这种渐进式演化和反复。当然服务模块本身需要支持可集中式部署，也可分布式部署。



> 企业应用系统可以申请停机维护，同时升级接口。但是网站服务不可能中断，因此分布式服务框架需要支持服务多版本发布，服务提供者先升级接口发布新版本的服务，并同时提供旧版本的服务供请求者调用，当请求者调用接口升级后才可以关闭旧版本服务。



> 据称Facebook利用Thrift（一个开源的远程服务调用框架）管理其分布式服务，服务的注册、发现及调用都通过Thrift完成，但对于一个大型网站可以使用的分布式服务框架，仅有Thrift还远远不够，遗憾的是，Facebook没有开源其基于Thrift的分布式服务框架。目前国内有较多成功实施案例的开源分布式服务框架是阿里巴巴的Dubbo（http://code.alibabatech.com/wiki/display/dubbo/Home/）。



## 7.4 可扩展的数据结构


## 7.5　利用开放平台建设网站生态圈


> 开放平台是网站内部和外部交互的接口，外部需要面对众多的第三方开发者，内部需要面对网站内诸多的业务服务。虽然每个网站的业务场景和需求都各不相同，但是开放平台的架构设计却大同小异，如图7.7所示。



![屏幕快照 2019-12-22 下午10.14.00.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1577024144806-03a17048-8934-4f1e-9a98-0d539f886514.png#align=left&display=inline&height=500&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-12-22%20%E4%B8%8B%E5%8D%8810.14.00.png&originHeight=1000&originWidth=764&size=195365&status=done&style=shadow&width=382)


## 7.6　小结


> 既然我们知道网站不停上新产品是其生存的本能，谁能更快更好地推出更多的新产品，谁就活得更滋润，那么工程师就要做好准备应付这种局面。马克思的劳动价值理论告诉我们，产品的内在价值在于劳动的时间，劳动的时间不在于个体付出的劳动时间，而在于行业一般劳动时间，资本家只会为行业一般劳动时间买单，如果你的效率低于行业一般劳动时间，对不起，请你自愿加班。反之，如果你有一个更具有扩展性的网站架构，可以更快速地开发新产品，也许你也享受不了只上半天班的福利，但是至少在这个全行业加班的互联网领域，你能够按时下班，陪陪家人，看看星星。



# 8 固若金汤：网站的安全架构


## 8.1　道高一尺魔高一丈的网站应用攻击与防御


### 8.1.1 XSS


> 攻击新浪微博的手段被称作XSS攻击，它和SQL注入攻击构成网站应用攻击最主要的两种手段，全球大约70％的Web应用攻击都来自XSS攻击和SQL注入攻击。此外，常用的Web应用还包括CSRF、Session劫持等手段。



> 常见的XSS攻击类型有两种，一种是反射型，攻击者诱使用户点击一个嵌入恶意脚本的链接，达到攻击的目的，如图8.1所示



> 另外一种XSS攻击是持久型XSS攻击，黑客提交含有恶意脚本的请求，保存在被攻击的Web站点的数据库中，用户浏览网页时，恶意脚本被包含在正常页面中，达到攻击的目的，如图8.2所示。



> 事实上，消毒几乎是所有网站最必备的XSS防攻击手段。



### 8.1.2 SQL注入


> 参数绑定
> 使用预编译手段，绑定参数是最好的防SQL注入方法。目前许多数据访问层框架，如IBatis，Hibernate等，都实现SQL预编译和参数绑定，攻击者的恶意SQL会被当做SQL的参数，而不是SQL命令被执行。
> 除了SQL注入，攻击者还根据具体应用，注入OS命令、编程语言代码等，利用程序漏洞，达到攻击目的。



### 8.1.3 CSRF攻击


> Referer check
> HTTP请求头的Referer域中记录着请求来源，可通过检查请求来源，验证其是否合法。很多网站使用这个功能实现图片防盗链（如果图片访问的页面来源不是来自自己网站的网页就拒绝）。



### 8.1.4 其他攻击方式


> 路径遍历
> 攻击者在请求的URL中使用相对路径，遍历系统未开放的目录和文件。防御方法主要是将JS、CSS等资源文件部署在独立服务器、使用独立域名，其他文件不使用静态URL访问，动态参数不包含文件路径信息。



## 8.2　信息加密技术及密钥安全管理


> 利用单向散列加密的这个特性，可以进行密码加密保存，即用户注册时输入的密码不直接保存到数据库，而是对密码进行单向散列加密，将密文存入数据库，用户登录时，进行密码验证，同样计算得到输入密码的密文，并和数据库中的密文比较，如果一致，则密码验证成功，具体过程如图8.7所示。



> 虽然不能通过算法将单向散列密文反算得到明文，但是由于人们设置密码具有一定的模式，因此通过彩虹表（人们常用密码和对应的密文关系表）等手段可以进行猜测式破解。
> 为了加强单向散列计算的安全性，还会给散列算法加点盐（salt），salt相当于加密的密钥，增加破解的难度。



## 8.3　信息过滤与反垃圾


> 那么如何快速地判断用户信息中是否含有敏感词呢？如果敏感词比较少，用户提交信息文本长度也较短，可直接使用正则表达式匹配。但是正则表达式的效率一般较差，当敏感词很多，用户发布的信息也很长，网站并发量较高时，就需要更合适的方法来完成，这方面公开的算法有很多，基本上都是Trie树的变种，空间和时间复杂度都比较好的有双数组Trie算法等。



> 另一种更简单的实现是通过构造多级Hash表进行文本匹配。



其实多级Hash表和Trie树思路是一样的。


> 在对过滤需求要求不完全精确的场景下，可用布隆过滤器代替Hash表。布隆过滤器是用它的发明者巴顿·布隆的名字命名的，通过一个二进制列表和一组随机数映射函数实现



> 仍以需要处理10亿邮件地址黑名单列表为例，在内存中建立一个2GB大小的存储空间，即16GB个二进制bit，并全部初始化为0。要将一个邮箱地址加入黑名单时，使用8个随机映射函数（F1,F2,…,F8）得到0~16GB范围内的8个随机数，从而将该邮箱地址映射到16GB二进制存储空间的8个位置上，然后将这些位置置为1。当要检查一个邮箱地址是否在黑名单中时，使用同样的映射函数，得到16GB空间8个位置上的bit，如果这些值都为1，那么该邮箱地址在黑名单中。



![屏幕快照 2019-12-22 下午10.40.48.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1577025754947-a6737269-522a-4b61-8f45-0e8f5e2483ba.png#align=left&display=inline&height=352&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-12-22%20%E4%B8%8B%E5%8D%8810.40.48.png&originHeight=704&originWidth=972&size=200254&status=done&style=shadow&width=486)


> 可以看到，处理同样数量的信息，布隆过滤器只使用Hash表所需内存的1/8。但是布隆过滤器有可能导致系统误判（布隆过滤器检查在黑名单中，但实际却并未放入过）。因为一个邮箱地址映射的8个bit可能正好都被其他邮箱地址设为1了，这种可能性极小，通常在系统可接受范围内。但如果需要精确的判断，则不适合使用布隆过滤器。





# 10　维基百科的高性能架构设计分析


> wikipedia.org不过只有区区数百台服务器，并仅由十余名技术人员维护，不得不说是一个奇迹。Wikipedia对资源的利用，对性能的优化很具有典型性，有许多值得学习的地方



## 10.1　Wikipedia网站整体架构


> Wikipedia的架构如图10.2所示。



![屏幕快照 2019-12-22 下午10.44.54.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1577026002217-1ffca12a-9b02-48c4-b107-63edcec70d04.png#align=left&display=inline&height=411&margin=%5Bobject%20Object%5D&name=%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-12-22%20%E4%B8%8B%E5%8D%8810.44.54.png&originHeight=822&originWidth=1192&size=498703&status=done&style=shadow&width=596)


> Lighttpd：开源的应用服务器，较主流的Apache服务器更轻量、更快速。实践中，有许多网站使用Lighttpd作为图片服务器。



> Memcached：无中心高性能的开源分布式缓存系统，稳定、可靠、历久弥新，是网站分布式缓存服务必备的。



## 10.2　Wikipedia性能优化策略


> •如果Master数据库宕机，立即将应用切换到Salve数据库，同时关闭数据写服务，这意味着关闭词条编辑功能。Wikipedia通过约束业务获得更大的技术方案选择余地，**很多时候业务后退一小步，技术就可以前进一大步。**



# 11  海量分布式存储系统Doris的高可用架构设计分析


## 11.1　分布式存储系统的高可用架构


> •管理中心服务器：这是一个由两台机器组成的主-主热备的小规模服务器集群，主要负责集群管理，对数据存储集群进行健康心跳检测；集群扩容、故障恢复管理；对应用程序服务器提供集群地址配置信息服务等。



## 11.2　不同故障情况下的高可用解决方案


> 对于一个分布式存储系统而言，影响系统整体可用性的故障可以分成以下三类。
> •瞬时故障：引起这类故障的主要原因是网络通信瞬时中断、服务器内存垃圾回收或后台线程繁忙停止数据访问操作响应。其特点是故障时间短，在秒级甚至毫秒级系统即可自行恢复正常响应。
> •临时故障：引起这类故障的主要原因是交换机宕机、网卡松动等导致的网络通信中断；系统升级、停机维护等一般运维活动引起的服务关闭；内存损坏、CPU过热等硬件原因导致的服务器宕机；这类故障的主要特点是需要人工干预（更换硬件、重启机器等）才能恢复正常。通常持续时间需要几十分钟甚至几小时。故障时间可分为两个阶段：临时故障期间，临时故障恢复期间。
> •永久故障：引起这类故障的主要原因只有一个：硬盘损坏，数据丢失。虽然损坏硬盘和损坏内存一样，可以通过更换硬盘来重新启动机器，但是丢失的数据却永远找不回来了，因此其处理策略也和前面两种故障完全不同，恢复系统到正常状态也需要更长的时间。故障时间可分为两个阶段：永久故障期间和永久故障恢复期间。



# 12　网购秒杀系统架构设计案例分析


> 网站的秒杀业务不能使用正常的网站业务流程，也不能和正常的网站交易业务共用服务器，必须设计部署专门的秒杀系统，进行专门应对。



> 秒杀活动只是网站营销的一个附加活动，这个活动具有时间短，并发访问量大的特点，如果和网站原有应用部署在一起，必然会对现有业务造成冲击，稍有不慎可能导致整个网站瘫痪。



## 12.2　秒杀系统的应对策略


> 12.2　秒杀系统的应对策略



### 1．秒杀系统独立部署


> 为了避免因为秒杀活动的高并发访问而拖垮整个网站，使整个网站不必面对蜂拥而来的用户访问，可将秒杀系统独立部署



### 2．秒杀商品页面静态化


> 重新设计秒杀商品页面，不使用网站原来的商品详情页面，页面内容静态化：将商品描述、商品参数、成交记录和用户评价全部写入一个静态页面，用户请求不需要经过应用服务器的业务逻辑处理，也不需要访问数据库。所以秒杀商品服务不需要部署动态的Web服务器和数据库服务器。



### 3．租借秒杀活动网络带宽


> 需要将秒杀商品页面缓存在CDN



### 4．动态生成随机下单页面URL


> 为了避免用户直接访问下单页面URL，需要将该URL动态化，即使秒杀系统的开发者也无法在秒杀开始前访问下单页面的URL。办法是在下单页面URL加入由服务器端生成的随机数作为参数，在秒杀开始的时候才能得到。



## 12.3    秒杀系统架构设计


### 2．如何只允许第一个提交的订单被发送到订单子系统


> 事实上，由于最终能够成功提交订单的用户只有一个，为了减轻下单页面服务器的负载压力，可以控制进入下单页面的入口，只有少数用户能进入下单页面，其他用户直接进入秒杀结束页面。假设下单服务器集群有10台服务器，每台服务器只接受最多10个下单请求，如图12.4所示。



![image.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1577083206305-cbde9774-49d3-4c2f-b46c-cb860caafbd8.png#align=left&display=inline&height=527&margin=%5Bobject%20Object%5D&name=image.png&originHeight=527&originWidth=486&size=75953&status=done&style=shadow&width=486)


# 13　大型网站典型故障案例分析


> 大型网站的技术本质都很简单，没有很花哨的东西，掌握起来也不难。大型网站的架构师最有价值的地方不在于他们掌握了多少技术，而在于他们经历过多少故障。每一次故障都会给公司带来难以估计的利益损失，所以培养一个网站架构师的成本不单要看付了他多少薪水，给了他多少股票，还要看为他引起的故障买了多少次单。



## 13.1　写日志也会引发故障


> 但是该应用的开发人员将log输出的level全局配置为Debug。这样一次简单的Web请求就会产生大量的log文件输出，在高并发的用户请求下，很快就消耗完不多的磁盘空间。



## 13.2　高并发访问数据库引发的故障


> •首页不应该访问数据库，首页需要的数据可以从缓存服务器或者搜索引擎服务器获取。
> •首页最好是静态的。



## 13.3　高并发情况下锁引发的故障


> •使用锁操作要谨慎。



## 13.4　缓存引发的故障


> 一个缺乏经验的工程师关闭了缓存服务器集群中全部的十几台Memcached服务器，导致了网站全部瘫痪的重大事故。



缓存雪崩


> •当缓存已经不仅仅是改善性能，而是成为网站架构不可或缺的一部分时，对缓存的管理就需要提高到和其他服务器一样的级别。



## 13.5　应用启动不同步引发的故障


注意各种服务间的依赖顺序。拓扑排序。


> 老鸨开门前要检查下姑娘们是否穿好了衣服。



???


## 13.6　大文件读写独占磁盘引发的故障


> 存储的使用需要根据不同文件类型和用途进行管理，图片都是小文件，应该使用专用的存储服务器，不能和大文件共用存储。批处理用的大文件可以使用其他类型的分布式文件系统。



## 13.7　滥用生产环境引发的故障


> 访问线上生产环境要规范，不小心就会导致大事故。



## 13.9　不好的编程习惯引发的故障


书中在此处谈到的是 null 的问题，编码过程中注意**空指针检查**或使用**空对象模式**。


# 14　架构师领导艺术


> 架构师是软件开发组织中一个比较特殊的角色，除了架构设计，软件开发等技术类工作，通常还需要承担一些管理职能：规划产品路线、估算人力资源和时间资源、安排人员职责分工，确定计划里程碑点、指导工程师工作、过程风险评估与控制等。这些管理事务需要对产品技术架构、功能模块划分、技术风险都熟悉的架构师参与或直接负责。



## 14.1　关注人而不是产品


> 最好的软件项目管理不是制订计划，组织资源，跟踪修正项目进展，对成员进行激励和惩罚，而是发掘项目组每个成员的优秀潜能，让大家理解并热爱软件产品最终的蓝图和愿景。每个人都是为实现自我价值而努力，不是为了领工资而工作。



> 这也是领导的真谛：寻找一个值得共同奋斗的目标，营造一个让大家都能最大限度发挥自我价值的工作氛围。



> 所有强迫员工加班的管理者都应该为自己的无能而羞愧。



## 14.2　发掘人的优秀


> 发掘人的优秀远比发掘优秀的人更有意义。



## 14.3　共享美好蓝图


> 14.3　共享美好蓝图



画饼的艺术，真的能做到确实太难。


> 蓝图应该是**表述清楚**的：产品要做什么、不做什么、要达到什么业务目标，都需要描述清楚。
> 蓝图应该是形象的：产品能为用户创造什么价值、能实现什么样的市场目标、产品最终会长什么样，都需要形象地想象出来。
> 蓝图应该是简单的：不管内部还是外部沟通，都能一句话说明白：我们在做什么。



可量化的目标


## 14.5　学会妥协


> 不要企图在项目中证明自己是正确的，一定要记住，你是来做软件的，不是来当老大的。所以不要企图去证明自己了不起，永远也别干这种浪费时间、伤害感情的事。



> 很多时候，对架构和技术方案的反对意见，其实意味着架构和技术方案被关注、被试图理解和接受。架构师不应该对意见过于敏感，这时架构师应该做的是坦率地分享自己的设计思路，让别人理解自己的想法并努力理解别人的想法，求同存异。



> 于技术细节的争论应该立即验证而不是继续讨论，当讨论深入到技术细节的时候也意味着问题已经收敛，对于整体架构设计，各方意见正趋于一致。



# 网站架构师职场攻略


## 15.1　发现问题，寻找突破


> 所谓问题，就是体验—期望，当体验不能满足期望，就会觉得出了问题。消除问题有两种手段：改善体验或者降低期望。**降低期望只是回避了问题，而如果直面期望和体验之间的差距，就会发现问题所在，找到突破点。**



> 新员工Tips
> 1．许多刚加入公司的新员工一开始就急着要做出成绩，但是由于不熟悉环境，四处碰壁，被打消了积极性，反而不利于长远发展。其实新员工首先要做的事情是融入团队，跟大家打成一片，只要能和团队一起共进退，你就不是一个人在战斗。等熟悉了情况，知道了水的深浅后，再寻找突破口，择机而动。
> 2．新员工最不需要做的事情就是证明自己的能力。在新环境中一时施展不开就怀疑自己的能力，进而担心被其他人怀疑自己的能力，于是努力想要证明自己，但是常常事与愿违，反而出乱子，伤害了公司和自己的利益。其实既然能经过层层考核和挑选进入公司，就已经证明你有和工作要求相匹配的能力，你要相信当初选中你的同事的眼光和能力。



> 做出软件不等于解决问题，事实上很多问题确实也不需要用软件来解决。



## 15.2　提出问题，寻求支持


> 把“我的问题”表述成“我们的问题”



> 给上司提封闭式问题，给下属提开放式问题



> 指出问题而不是批评人



> 所谓直言有讳是指想要表达的意图要直截了当说明白，不要兜圈子，但是在表达方式上要有所避讳，照顾到当事人的感受。



## 15.3　解决问题，达成绩效


> 适当的逃避问题
> 有时候，有些人会提出一些不怎么靠谱的问题和方案。比如，一个急着要表现自己能力和价值的新员工，你如果和他直接说“不行”，会挫伤他的积极性，而他经过一段时间的磨合和思考，会自己意识到不可行。
> 对于这种情况，适当逃避问题，将事情搁置起来是最好的办法。
> “我去开个会，我们回来再谈。”
> “这个idea非常好，我们改天组织一个会议好好讨论一下……”



听着好像很有道理但是又不太对。


# 附录A　大型网站架构技术一览


附录A是常用架构技术总结，内容不多，但是是全书最精华的部分了，列举了技术架构的方方面面


> 网站系统架构层次如图A.1所示。



![image.png](https://cdn.nlark.com/yuque/0/2019/png/657413/1577085176980-ed7f798b-b6fc-4ca0-885f-8c19a90be7d2.png#align=left&display=inline&height=561&margin=%5Bobject%20Object%5D&name=image.png&originHeight=561&originWidth=674&size=79379&status=done&style=none&width=674)


## 前端架构


> 浏览器优化技术
> 并不是优化浏览器，而是通过优化响应页面，加快浏览器页面的加载和显示，常用的有页面缓存、合并HTTP减少请求次数、使用页面压缩等。
> CDN
> 内容分发网络，部署在网络运营商机房，通过将静态页面内容分发到离用户最近的CDN服务器，使用户可以通过最短路径获取内容。
> 动静分离，静态资源独立部署
> 静态资源，如JS、CSS等文件部署在专门的服务器集群上，和Web应用动态内容服务分离，并使用专门的（二级）域名。
> 图片服务
> 图片不是指网站Logo、按钮图标等，这些文件属于上面提到的静态资源，应该和JS、CSS部署在一起。这里的图片指用户上传的图片，如产品图片、用户头像等，图片服务同样使用独立部署的图片服务器集群，并使用独立（二级）域名。
> 反向代理
> 部署在网站机房，在应用服务器、静态资源服务器、图片服务器之前，提供页面缓存服务。
> DNS
> 域名服务，将域名解析成IP地址，利用DNS可以实现DNS负载均衡，配置CDN也需要修改DNS，使域名解析后指向CDN服务器。



## 应用层架构


具体的业务逻辑层


> 开发框架
> 网站业务是多变的，网站的大部分软件工程师都是在加班加点开发网站业务，一个好的开发框架至关重要。一个好的开发框架应该能够分离关注面，使美工、开发工程师可以各司其事，易于协作。同时还应该内置一些安全策略，防护Web应用攻击。
> 页面渲染
> 将分别开发维护的动态内容和静态页面模板集成起来，组合成最终显示给用户的完整页面。
> 负载均衡
> 将多台应用服务器组成一个集群，通过负载均衡技术将用户请求分发到不同的服务器上，以应对大量用户同时访问时产生的高并发负载压力。
> Session管理
> 为了实现高可用的应用服务器集群，应用服务器通常设计为无状态，不保存用户请求上下文信息，但是网站业务通常需要保持用户会话信息，需要专门的机制管理Session，使集群内甚至跨集群的应用服务器可以共享Session。
> 动态页面静态化

> 对于访问量特别大而更新又不很频繁的动态页面，可以将其静态化，即生成一个静态页面，利用静态页面的优化手段加速用户访问，如反向代理、CDN、浏览器缓存等。
> 业务拆分

> 将复杂而又庞大的业务拆分开来，形成多个规模较小的产品，独立开发、部署、维护，除了降低系统耦合度，也便于数据库业务分库。按业务对关系数据库进行拆分，技术难度相对较小，而效果又相对较好。

> 虚拟化服务器

> 将一台物理服务器虚拟化成多台虚拟服务器，对于并发访问较低的业务，更容易用较少的资源构建高可用的应用服务器集群。



## 服务层架构


可复用的基础服务层


> 提供基础服务，供应用层调用，完成网站业务。

> 分布式消息

> 利用消息队列机制，实现业务和业务、业务和服务之间的异步消息发送及低耦合的业务关系。

> 分布式服务

> 提供高性能、低耦合、易复用、易管理的分布式服务，在网站实现面向服务架构（SOA）。

> 分布式缓存

> 通过可伸缩的服务器集群提供大规模热点数据的缓存服务，是网站性能优化的重要手段。

> 分布式配置

> 系统运行需要配置许多参数，如果这些参数需要修改，比如分布式缓存集群加入新的缓存服务器，需要修改应用程序客户端的缓存服务器列表配置，并重启应用程序服务器。分布式配置在系统运行期提供配置动态推送服务，将配置修改实时推送到应用系统，无需重启服务器。



## 存储层架构


> 提供数据、文件的持久化存储访问与管理服务。

> 分布式文件

> 网站在线业务需要存储的文件大部分都是图片、网页、视频等比较小的文件，但是这些文件的数量非常庞大，而且通常都在持续增加，需要伸缩性设计比较好的分布式文件系统。

> 关系数据库

> 大部分网站的主要业务是基于关系数据库开发的，但是关系数据库对集群伸缩性的支持比较差。通过在应用程序的数据访问层增加数据库访问路由功能，根据业务配置将数据库访问路由到不同的物理数据库上，可实现关系数据库的分布式访问。

> NoSQL数据库

> 目前各种NoSQL数据库层出不穷，在内存管理、数据模型、集群分布式管理等方面各有优势，不过从社区活跃性角度看，HBase无疑是目前最好的。

> 数据同步

> 在支持全球范围内数据共享的分布式数据库技术成熟之前，拥有多个数据中心的网站必须在多个数据中心之间进行数据同步，以保证每个数据中心都拥有完整的数据。在实践中，为了减轻数据库压力，将数据库的事务日志（或者NoSQL的写操作Log）同步到其他数据中心，根据Log进行数据重演，实现数据同步。



后台架构

> 网站应用中，除了要处理用户的实时访问请求外，还有一些后台非实时数据分析要处理。

> 搜索引擎

> 即使是网站内部的搜索引擎，也需要进行数据增量更新及全量更新、构建索引等。这些操作通过后台系统定时执行。

> 数据仓库

> 根据离线数据，提供数据分析与数据挖掘服务。

> 推荐系统

> 社交网站及购物网站通过挖掘人和人之间的关系，人和商品之间的关系，发掘潜在的人际关系和购物兴趣，为用户提供个性化推荐服务。



## 数据采集与监控


> 监控网站访问情况与系统运行情况，为网站运营决策和运维管理提供支持保障。
> 


> 浏览器数据采集

> 通过在网站页面中嵌入JS脚本采集用户浏览器环境与操作记录，分析用户行为。
> 


> 服务器业务数据采集

> 服务器业务数据包括两种，一种是采集在服务器端记录的用户请求操作日志；一种是采集应用程序运行期业务数据，比如待处理消息数目等。
> 


> 服务器性能数据采集

> 采集服务器性能数据，如系统负载、内存使用率、网卡流量等。
> 


> 系统监控

> 将前述采集的数据以图表的方式展示，以便运营和运维人员监控网站运行状况，做到这一步仅仅是系统监视。更先进的做法是根据采集的数据进行自动化运维，自动处理系统异常状况，实现自动化控制。
> 


> 系统报警

> 如果采集来的数据超过预设的正常情况的阈值，比如系统负载过高，就通过邮件、短信、语音电话等方式发出报警信号，等待工程师干预。

# 
# 附录B　Web开发技术发展历程


> 这种层次划分是逻辑上的，物理部署上多个层会作为一个应用部署在一起。



# 后记


> 不要企图去设计一个大型网站！



> 互联网正在并将继续改变这个世界，一切才刚刚开始，你我正生逢其时！



